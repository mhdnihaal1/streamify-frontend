import { simd } from 'wasm-feature-detect';
import { WorkerTimer } from '@stream-io/worker-timer';
import { FilesetResolver, ImageSegmenter } from '@mediapipe/tasks-vision';

/**
 * Checks if the current platform is a mobile device.
 *
 * See:
 * https://developer.mozilla.org/en-US/docs/Web/HTTP/Browser_detection_using_the_user_agent
 */
const isMobile = () => /Mobi/i.test(navigator.userAgent);
/**
 * Checks whether the current browser is Safari.
 */
const isSafari = () => /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
/**
 * Runs a check to see if the current platform supports
 * the necessary APIs required for the video filters.
 */
const isPlatformSupported = async ({ forceMobileSupport = false, forceSafariSupport = false, } = {}) => typeof document !== 'undefined' &&
    typeof window !== 'undefined' &&
    typeof navigator !== 'undefined' &&
    // we don't support mobile devices yet due to performance issues
    (forceMobileSupport || !isMobile()) &&
    // Safari has issues with timer throttling, causing low FPS when the tab goes to the background
    (forceSafariSupport || !isSafari()) &&
    typeof WebAssembly !== 'undefined' &&
    !!window.WebGL2RenderingContext && // WebGL2 is required for the video filters
    !!document.createElement('canvas').getContext('webgl2') &&
    (await simd()); // SIMD is required for the wasm module
/**
 * Runs a check to see if the current platform supports
 * the necessary APIs required for the MediaPipe-based video filters.
 */
const isMediaPipePlatformSupported = async ({ forceMobileSupport = false, forceSafariSupport = false, } = {}) => typeof document !== 'undefined' &&
    typeof window !== 'undefined' &&
    typeof navigator !== 'undefined' &&
    // we don't support mobile devices yet due to performance issues
    (forceMobileSupport || !isMobile()) &&
    // Safari has issues with timer throttling, causing low FPS when the tab goes to the background
    (forceSafariSupport || !isSafari()) &&
    typeof WebAssembly !== 'undefined' &&
    typeof OffscreenCanvas !== 'undefined' && // OffscreenCanvas is required for efficient rendering
    !!window.WebGL2RenderingContext && // WebGL2 is required for the video filters
    !!new OffscreenCanvas(1, 1).getContext('webgl2') &&
    typeof VideoFrame !== 'undefined' && // VideoFrame API is required for frame processing
    typeof createImageBitmap !== 'undefined'; // createImageBitmap is required for background image processing

/**
 * Use it along with boyswan.glsl-literal VSCode extension
 * to get GLSL syntax highlighting.
 * https://marketplace.visualstudio.com/items?itemName=boyswan.glsl-literal
 *
 * On VSCode OSS, boyswan.glsl-literal requires slevesque.shader extension
 * to be installed as well.
 * https://marketplace.visualstudio.com/items?itemName=slevesque.shader
 */
const glsl = String.raw;
function createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer) {
    const program = createProgram(gl, vertexShader, fragmentShader);
    const positionAttributeLocation = gl.getAttribLocation(program, 'a_position');
    gl.enableVertexAttribArray(positionAttributeLocation);
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);
    const texCoordAttributeLocation = gl.getAttribLocation(program, 'a_texCoord');
    gl.enableVertexAttribArray(texCoordAttributeLocation);
    gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
    gl.vertexAttribPointer(texCoordAttributeLocation, 2, gl.FLOAT, false, 0, 0);
    return program;
}
function createProgram(gl, vertexShader, fragmentShader) {
    const program = gl.createProgram();
    gl.attachShader(program, vertexShader);
    gl.attachShader(program, fragmentShader);
    gl.linkProgram(program);
    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        throw new Error(`Could not link WebGL program: ${gl.getProgramInfoLog(program)}`);
    }
    return program;
}
function compileShader(gl, shaderType, shaderSource) {
    const shader = gl.createShader(shaderType);
    gl.shaderSource(shader, shaderSource);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        throw new Error(`Could not compile shader: ${gl.getShaderInfoLog(shader)}`);
    }
    return shader;
}
function createTexture(gl, internalformat, width, height, minFilter = gl.NEAREST, magFilter = gl.NEAREST) {
    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, minFilter);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, magFilter);
    gl.texStorage2D(gl.TEXTURE_2D, 1, internalformat, width, height);
    return texture;
}
async function readPixelsAsync(gl, x, y, width, height, format, type, dest) {
    const buf = gl.createBuffer();
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
    gl.bufferData(gl.PIXEL_PACK_BUFFER, dest.byteLength, gl.STREAM_READ);
    gl.readPixels(x, y, width, height, format, type, 0);
    gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);
    await getBufferSubDataAsync(gl, gl.PIXEL_PACK_BUFFER, buf, 0, dest);
    gl.deleteBuffer(buf);
    return dest;
}
async function getBufferSubDataAsync(gl, target, buffer, srcByteOffset, dstBuffer, dstOffset, length) {
    const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
    gl.flush();
    if (!sync)
        return;
    const res = await clientWaitAsync(gl, sync);
    gl.deleteSync(sync);
    if (res !== gl.WAIT_FAILED) {
        gl.bindBuffer(target, buffer);
        gl.getBufferSubData(target, srcByteOffset, dstBuffer, dstOffset, length);
        gl.bindBuffer(target, null);
    }
}
function clientWaitAsync(gl, sync) {
    return new Promise((resolve) => {
        function test() {
            const res = gl.clientWaitSync(sync, 0, 0);
            if (res === gl.WAIT_FAILED) {
                resolve(res);
                return;
            }
            if (res === gl.TIMEOUT_EXPIRED) {
                setTimeout(test);
                return;
            }
            resolve(res);
        }
        setTimeout(test);
    });
}

function buildBackgroundBlurStage(gl, vertexShader, positionBuffer, texCoordBuffer, personMaskTexture, canvas, blurLevel) {
    const blurPass = buildBlurPass(gl, vertexShader, positionBuffer, texCoordBuffer, personMaskTexture, canvas, blurLevel);
    const blendPass = buildBlendPass(gl, positionBuffer, texCoordBuffer, canvas);
    function render() {
        blurPass.render();
        blendPass.render();
    }
    function updateCoverage(coverage) {
        blendPass.updateCoverage(coverage);
    }
    function cleanUp() {
        blendPass.cleanUp();
        blurPass.cleanUp();
    }
    return {
        render,
        updateCoverage,
        cleanUp,
    };
}
function buildBlurPass(gl, vertexShader, positionBuffer, texCoordBuffer, personMaskTexture, canvas, blurLevel) {
    const sigma = typeof blurLevel === 'number'
        ? blurLevel
        : blurLevel === 'low'
            ? 2
            : blurLevel === 'medium'
                ? 4
                : 6;
    const windowSize = Math.max(1, Math.floor(sigma * 3));
    const offset = new Array(windowSize).fill(0).map((v, index) => index);
    const variance = sigma ** 2;
    const weights = offset.map((x) => {
        const m = sigma * Math.sqrt(2 * Math.PI);
        const e = Math.exp(-(x ** 2) / (2 * variance));
        return e / m;
    });
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;

    uniform sampler2D u_inputFrame;
    uniform sampler2D u_personMask;
    uniform vec2 u_texelSize;

    in vec2 v_texCoord;
    out vec4 outColor;

    const float offset[${windowSize}] = float[](${offset.map((i) => i.toFixed(10)).join(', ')});
    const float weight[${windowSize}] = float[](${weights.map((i) => i.toFixed(10)).join(', ')});

    void main() {
      vec4 centerColor = texture(u_inputFrame, v_texCoord);
      float personMask = texture(u_personMask, v_texCoord).a;

      vec4 frameColor = centerColor * weight[0] * (1.0 - personMask);

      for (int i = 1; i < ${windowSize}; i++) {
        vec2 offset = vec2(offset[i]) * u_texelSize;

        vec2 texCoord = v_texCoord + offset;
        frameColor += texture(u_inputFrame, texCoord)
           * weight[i]
           * (1.0 - texture(u_personMask, texCoord).a);

        texCoord = v_texCoord - offset;
        frameColor += texture(u_inputFrame, texCoord)
          * weight[i]
          * (1.0 - texture(u_personMask, texCoord).a);
      }
      outColor = vec4(frameColor.rgb + (1.0 - frameColor.a) * centerColor.rgb, 1.0);
    }
  `;
    const scale = 0.5;
    const outputWidth = canvas.width * scale;
    const outputHeight = canvas.height * scale;
    const texelWidth = 1 / outputWidth;
    const texelHeight = 1 / outputHeight;
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const inputFrameLocation = gl.getUniformLocation(program, 'u_inputFrame');
    const personMaskLocation = gl.getUniformLocation(program, 'u_personMask');
    const texelSizeLocation = gl.getUniformLocation(program, 'u_texelSize');
    const texture1 = createTexture(gl, gl.RGBA8, outputWidth, outputHeight, gl.NEAREST, 
    // @ts-expect-error types are incomplete
    gl.LINEAR);
    const texture2 = createTexture(gl, gl.RGBA8, outputWidth, outputHeight, gl.NEAREST, 
    // @ts-expect-error types are incomplete
    gl.LINEAR);
    const frameBuffer1 = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer1);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture1, 0);
    const frameBuffer2 = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer2);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture2, 0);
    gl.useProgram(program);
    gl.uniform1i(personMaskLocation, 1);
    function render() {
        gl.viewport(0, 0, outputWidth, outputHeight);
        gl.useProgram(program);
        gl.uniform1i(inputFrameLocation, 0);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, personMaskTexture);
        for (let i = 0; i < 3; i++) {
            gl.uniform2f(texelSizeLocation, 0, texelHeight);
            gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer1);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            gl.activeTexture(gl.TEXTURE2);
            gl.bindTexture(gl.TEXTURE_2D, texture1);
            gl.uniform1i(inputFrameLocation, 2);
            gl.uniform2f(texelSizeLocation, texelWidth, 0);
            gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer2);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
            gl.bindTexture(gl.TEXTURE_2D, texture2);
        }
    }
    function cleanUp() {
        gl.deleteFramebuffer(frameBuffer2);
        gl.deleteFramebuffer(frameBuffer1);
        gl.deleteTexture(texture2);
        gl.deleteTexture(texture1);
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
    }
    return {
        render,
        cleanUp,
    };
}
function buildBlendPass(gl, positionBuffer, texCoordBuffer, canvas) {
    const vertexShaderSource = glsl `#version 300 es

    in vec2 a_position;
    in vec2 a_texCoord;

    out vec2 v_texCoord;

    void main() {
      // Flipping Y is required when rendering to canvas
      gl_Position = vec4(a_position * vec2(1.0, -1.0), 0.0, 1.0);
      v_texCoord = a_texCoord;
    }
  `;
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;

    uniform sampler2D u_inputFrame;
    uniform sampler2D u_personMask;
    uniform sampler2D u_blurredInputFrame;
    uniform vec2 u_coverage;

    in vec2 v_texCoord;

    out vec4 outColor;

    void main() {
      vec3 color = texture(u_inputFrame, v_texCoord).rgb;
      vec3 blurredColor = texture(u_blurredInputFrame, v_texCoord).rgb;
      float personMask = texture(u_personMask, v_texCoord).a;
      personMask = smoothstep(u_coverage.x, u_coverage.y, personMask);
      outColor = vec4(mix(blurredColor, color, personMask), 1.0);
    }
  `;
    const { width: outputWidth, height: outputHeight } = canvas;
    const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const inputFrameLocation = gl.getUniformLocation(program, 'u_inputFrame');
    const personMaskLocation = gl.getUniformLocation(program, 'u_personMask');
    const blurredInputFrame = gl.getUniformLocation(program, 'u_blurredInputFrame');
    const coverageLocation = gl.getUniformLocation(program, 'u_coverage');
    gl.useProgram(program);
    gl.uniform1i(inputFrameLocation, 0);
    gl.uniform1i(personMaskLocation, 1);
    gl.uniform1i(blurredInputFrame, 2);
    gl.uniform2f(coverageLocation, 0, 1);
    function render() {
        gl.viewport(0, 0, outputWidth, outputHeight);
        gl.useProgram(program);
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }
    function updateCoverage(coverage) {
        gl.useProgram(program);
        gl.uniform2f(coverageLocation, coverage[0], coverage[1]);
    }
    function cleanUp() {
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
        gl.deleteShader(vertexShader);
    }
    return {
        render,
        updateCoverage,
        cleanUp,
    };
}

function buildBackgroundImageStage(gl, positionBuffer, texCoordBuffer, personMaskTexture, backgroundImage, canvas) {
    const vertexShaderSource = glsl `#version 300 es

    uniform vec2 u_backgroundScale;
    uniform vec2 u_backgroundOffset;

    in vec2 a_position;
    in vec2 a_texCoord;

    out vec2 v_texCoord;
    out vec2 v_backgroundCoord;

    void main() {
      // Flipping Y is required when rendering to canvas
      gl_Position = vec4(a_position * vec2(1.0, -1.0), 0.0, 1.0);
      v_texCoord = a_texCoord;
      v_backgroundCoord = a_texCoord * u_backgroundScale + u_backgroundOffset;
    }
  `;
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;

    uniform sampler2D u_inputFrame;
    uniform sampler2D u_personMask;
    uniform sampler2D u_background;
    uniform vec2 u_coverage;
    uniform float u_lightWrapping;
    uniform float u_blendMode;

    in vec2 v_texCoord;
    in vec2 v_backgroundCoord;

    out vec4 outColor;

    vec3 screen(vec3 a, vec3 b) {
      return 1.0 - (1.0 - a) * (1.0 - b);
    }

    vec3 linearDodge(vec3 a, vec3 b) {
      return a + b;
    }

    void main() {
      vec3 frameColor = texture(u_inputFrame, v_texCoord).rgb;
      vec3 backgroundColor = texture(u_background, v_backgroundCoord).rgb;
      float personMask = texture(u_personMask, v_texCoord).a;
      float lightWrapMask = 1.0 - max(0.0, personMask - u_coverage.y) / (1.0 - u_coverage.y);
      vec3 lightWrap = u_lightWrapping * lightWrapMask * backgroundColor;

      frameColor = u_blendMode * linearDodge(frameColor, lightWrap)
        + (1.0 - u_blendMode) * screen(frameColor, lightWrap);
      personMask = smoothstep(u_coverage.x, u_coverage.y, personMask);
      outColor = vec4(frameColor * personMask + backgroundColor * (1.0 - personMask), 1.0);
    }
  `;
    const { width: outputWidth, height: outputHeight } = canvas;
    const outputRatio = outputWidth / outputHeight;
    const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const backgroundScaleLocation = gl.getUniformLocation(program, 'u_backgroundScale');
    const backgroundOffsetLocation = gl.getUniformLocation(program, 'u_backgroundOffset');
    const inputFrameLocation = gl.getUniformLocation(program, 'u_inputFrame');
    const personMaskLocation = gl.getUniformLocation(program, 'u_personMask');
    const backgroundLocation = gl.getUniformLocation(program, 'u_background');
    const coverageLocation = gl.getUniformLocation(program, 'u_coverage');
    const lightWrappingLocation = gl.getUniformLocation(program, 'u_lightWrapping');
    const blendModeLocation = gl.getUniformLocation(program, 'u_blendMode');
    gl.useProgram(program);
    gl.uniform2f(backgroundScaleLocation, 1, 1);
    gl.uniform2f(backgroundOffsetLocation, 0, 0);
    gl.uniform1i(inputFrameLocation, 0);
    gl.uniform1i(personMaskLocation, 1);
    gl.uniform2f(coverageLocation, 0, 1);
    gl.uniform1f(lightWrappingLocation, 0);
    gl.uniform1f(blendModeLocation, 0);
    let backgroundTexture = null;
    // TODO Find a better to handle background being loaded
    if (backgroundImage?.complete) {
        updateBackgroundImage(backgroundImage);
    }
    else if (backgroundImage) {
        backgroundImage.onload = () => {
            updateBackgroundImage(backgroundImage);
        };
    }
    function render() {
        gl.viewport(0, 0, outputWidth, outputHeight);
        gl.useProgram(program);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, personMaskTexture);
        if (backgroundTexture !== null) {
            gl.activeTexture(gl.TEXTURE2);
            gl.bindTexture(gl.TEXTURE_2D, backgroundTexture);
            // TODO Handle correctly the background not loaded yet
            gl.uniform1i(backgroundLocation, 2);
        }
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }
    function updateBackgroundImage(bgImage) {
        backgroundTexture = createTexture(gl, gl.RGBA8, bgImage.naturalWidth, bgImage.naturalHeight, 
        // @ts-expect-error types are incomplete
        gl.LINEAR, gl.LINEAR);
        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, bgImage.naturalWidth, bgImage.naturalHeight, gl.RGBA, gl.UNSIGNED_BYTE, bgImage);
        let xOffset = 0;
        let yOffset = 0;
        let backgroundWidth = bgImage.naturalWidth;
        let backgroundHeight = bgImage.naturalHeight;
        const backgroundRatio = backgroundWidth / backgroundHeight;
        if (backgroundRatio < outputRatio) {
            backgroundHeight = backgroundWidth / outputRatio;
            yOffset = (bgImage.naturalHeight - backgroundHeight) / 2;
        }
        else {
            backgroundWidth = backgroundHeight * outputRatio;
            xOffset = (bgImage.naturalWidth - backgroundWidth) / 2;
        }
        const xScale = backgroundWidth / bgImage.naturalWidth;
        const yScale = backgroundHeight / bgImage.naturalHeight;
        xOffset /= bgImage.naturalWidth;
        yOffset /= bgImage.naturalHeight;
        gl.uniform2f(backgroundScaleLocation, xScale, yScale);
        gl.uniform2f(backgroundOffsetLocation, xOffset, yOffset);
    }
    function updateCoverage(coverage) {
        gl.useProgram(program);
        gl.uniform2f(coverageLocation, coverage[0], coverage[1]);
    }
    function updateLightWrapping(lightWrapping) {
        gl.useProgram(program);
        gl.uniform1f(lightWrappingLocation, lightWrapping);
    }
    function updateBlendMode(blendMode) {
        gl.useProgram(program);
        gl.uniform1f(blendModeLocation, blendMode === 'screen' ? 0 : 1);
    }
    function cleanUp() {
        gl.deleteTexture(backgroundTexture);
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
        gl.deleteShader(vertexShader);
    }
    return {
        render,
        updateCoverage,
        updateLightWrapping,
        updateBlendMode,
        cleanUp,
    };
}

function buildJointBilateralFilterStage(gl, vertexShader, positionBuffer, texCoordBuffer, inputTexture, outputTexture, canvas, segmentationConfig) {
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;

    uniform sampler2D u_inputFrame;
    uniform sampler2D u_segmentationMask;
    uniform vec2 u_texelSize;
    uniform float u_step;
    uniform float u_radius;
    uniform float u_offset;
    uniform float u_sigmaTexel;
    uniform float u_sigmaColor;

    in vec2 v_texCoord;
    out vec4 outColor;

    float gaussian(float x, float sigma) {
      float coeff = -0.5 / (sigma * sigma * 4.0 + 1.0e-6);
      return exp((x * x) * coeff);
    }

    void main() {
      vec2 centerCoord = v_texCoord;
      vec3 centerColor = texture(u_inputFrame, centerCoord).rgb;
      float newVal = 0.0;

      float spaceWeight = 0.0;
      float colorWeight = 0.0;
      float totalWeight = 0.0;

      // Subsample kernel space.
      for (float i = -u_radius + u_offset; i <= u_radius; i += u_step) {
        for (float j = -u_radius + u_offset; j <= u_radius; j += u_step) {
          vec2 shift = vec2(j, i) * u_texelSize;
          vec2 coord = vec2(centerCoord + shift);
          vec3 frameColor = texture(u_inputFrame, coord).rgb;
          float outVal = texture(u_segmentationMask, coord).a;

          spaceWeight = gaussian(distance(centerCoord, coord), u_sigmaTexel);
          colorWeight = gaussian(distance(centerColor, frameColor), u_sigmaColor);
          totalWeight += spaceWeight * colorWeight;

          newVal += spaceWeight * colorWeight * outVal;
        }
      }
      newVal /= totalWeight;

      outColor = vec4(vec3(0.0), newVal);
    }
  `;
    const { width: segmentationWidth, height: segmentationHeight } = segmentationConfig;
    const { width: outputWidth, height: outputHeight } = canvas;
    const texelWidth = 1 / outputWidth;
    const texelHeight = 1 / outputHeight;
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const inputFrameLocation = gl.getUniformLocation(program, 'u_inputFrame');
    const segmentationMaskLocation = gl.getUniformLocation(program, 'u_segmentationMask');
    const texelSizeLocation = gl.getUniformLocation(program, 'u_texelSize');
    const stepLocation = gl.getUniformLocation(program, 'u_step');
    const radiusLocation = gl.getUniformLocation(program, 'u_radius');
    const offsetLocation = gl.getUniformLocation(program, 'u_offset');
    const sigmaTexelLocation = gl.getUniformLocation(program, 'u_sigmaTexel');
    const sigmaColorLocation = gl.getUniformLocation(program, 'u_sigmaColor');
    const frameBuffer = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, outputTexture, 0);
    gl.useProgram(program);
    gl.uniform1i(inputFrameLocation, 0);
    gl.uniform1i(segmentationMaskLocation, 1);
    gl.uniform2f(texelSizeLocation, texelWidth, texelHeight);
    // Ensures default values are configured to prevent infinite
    // loop in fragment shader
    updateSigmaSpace(0);
    updateSigmaColor(0);
    function render() {
        gl.viewport(0, 0, outputWidth, outputHeight);
        gl.useProgram(program);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, inputTexture);
        gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }
    function updateSigmaSpace(sigmaSpace) {
        sigmaSpace *= Math.max(outputWidth / segmentationWidth, outputHeight / segmentationHeight);
        const kSparsityFactor = 0.66; // Higher is sparser.
        const step = Math.max(1, Math.sqrt(sigmaSpace) * kSparsityFactor);
        const radius = sigmaSpace;
        const offset = step > 1 ? step * 0.5 : 0;
        const sigmaTexel = Math.max(texelWidth, texelHeight) * sigmaSpace;
        gl.useProgram(program);
        gl.uniform1f(stepLocation, step);
        gl.uniform1f(radiusLocation, radius);
        gl.uniform1f(offsetLocation, offset);
        gl.uniform1f(sigmaTexelLocation, sigmaTexel);
    }
    function updateSigmaColor(sigmaColor) {
        gl.useProgram(program);
        gl.uniform1f(sigmaColorLocation, sigmaColor);
    }
    function cleanUp() {
        gl.deleteFramebuffer(frameBuffer);
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
    }
    return { render, updateSigmaSpace, updateSigmaColor, cleanUp };
}

function buildResizingStage(gl, vertexShader, positionBuffer, texCoordBuffer, tflite, segmentationConfig, onError) {
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;
    uniform sampler2D u_inputFrame;
    in vec2 v_texCoord;
    out vec4 outColor;

    void main() {
      outColor = texture(u_inputFrame, v_texCoord);
    }
  `;
    // TFLite memory will be accessed as float32
    const tfliteInputMemoryOffset = tflite._getInputMemoryOffset() / 4;
    const { width: outputWidth, height: outputHeight } = segmentationConfig;
    const outputPixelCount = outputWidth * outputHeight;
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const inputFrameLocation = gl.getUniformLocation(program, 'u_inputFrame');
    const outputTexture = createTexture(gl, gl.RGBA8, outputWidth, outputHeight);
    const frameBuffer = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, outputTexture, 0);
    const outputPixels = new Uint8Array(outputPixelCount * 4);
    gl.useProgram(program);
    gl.uniform1i(inputFrameLocation, 0);
    function render() {
        gl.viewport(0, 0, outputWidth, outputHeight);
        gl.useProgram(program);
        gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
        // Downloads pixels asynchronously from GPU while rendering the current frame.
        // The pixels will be available in the next frame render which results
        // in offsets in the segmentation output but increases the frame rate.
        readPixelsAsync(gl, 0, 0, outputWidth, outputHeight, gl.RGBA, gl.UNSIGNED_BYTE, outputPixels).catch((error) => {
        });
        for (let i = 0; i < outputPixelCount; i++) {
            const tfliteIndex = tfliteInputMemoryOffset + i * 3;
            const outputIndex = i * 4;
            tflite.HEAPF32[tfliteIndex] = outputPixels[outputIndex] / 255;
            tflite.HEAPF32[tfliteIndex + 1] = outputPixels[outputIndex + 1] / 255;
            tflite.HEAPF32[tfliteIndex + 2] = outputPixels[outputIndex + 2] / 255;
        }
    }
    function cleanUp() {
        gl.deleteFramebuffer(frameBuffer);
        gl.deleteTexture(outputTexture);
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
    }
    return { render, cleanUp };
}

function buildSoftmaxStage(gl, vertexShader, positionBuffer, texCoordBuffer, tflite, outputTexture, segmentationConfig) {
    const fragmentShaderSource = glsl `#version 300 es

    precision highp float;

    uniform sampler2D u_inputSegmentation;
    in vec2 v_texCoord;
    out vec4 outColor;

    void main() {
      vec2 segmentation = texture(u_inputSegmentation, v_texCoord).rg;
      float shift = max(segmentation.r, segmentation.g);
      float backgroundExp = exp(segmentation.r - shift);
      float personExp = exp(segmentation.g - shift);
      outColor = vec4(vec3(0.0), personExp / (backgroundExp + personExp));
    }
  `;
    // TFLite memory will be accessed as float32
    const tfliteOutputMemoryOffset = tflite._getOutputMemoryOffset() / 4;
    const { width: segmentationWidth, height: segmentationHeight } = segmentationConfig;
    const fragmentShader = compileShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
    const program = createPipelineStageProgram(gl, vertexShader, fragmentShader, positionBuffer, texCoordBuffer);
    const inputLocation = gl.getUniformLocation(program, 'u_inputSegmentation');
    const inputTexture = createTexture(gl, gl.RG32F, segmentationWidth, segmentationHeight);
    const frameBuffer = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, outputTexture, 0);
    gl.useProgram(program);
    gl.uniform1i(inputLocation, 1);
    function render() {
        gl.viewport(0, 0, segmentationWidth, segmentationHeight);
        gl.useProgram(program);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, inputTexture);
        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, segmentationWidth, segmentationHeight, gl.RG, gl.FLOAT, tflite.HEAPF32, tfliteOutputMemoryOffset);
        gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }
    function cleanUp() {
        gl.deleteFramebuffer(frameBuffer);
        gl.deleteTexture(inputTexture);
        gl.deleteProgram(program);
        gl.deleteShader(fragmentShader);
    }
    return { render, cleanUp };
}

function buildWebGL2Pipeline(videoSource, backgroundImage, blurLevel, backgroundFilter, canvas, tflite, segmentationConfig, onError) {
    const gl = canvas.getContext('webgl2');
    if (!gl)
        throw new Error('WebGL2 is not supported');
    if (gl.isContextLost())
        throw new Error('WebGL2 context was lost');
    const { width: frameWidth, height: frameHeight } = videoSource;
    const { width: segmentationWidth, height: segmentationHeight } = segmentationConfig;
    const vertexShaderSource = glsl `#version 300 es

    in vec2 a_position;
    in vec2 a_texCoord;
    out vec2 v_texCoord;

    void main() {
      gl_Position = vec4(a_position, 0.0, 1.0);
      v_texCoord = a_texCoord;
    }
  `;
    const vertexShader = compileShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
    const vertexArray = gl.createVertexArray();
    gl.bindVertexArray(vertexArray);
    const positionBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1.0, -1, -1, 1.0, 1.0, 1.0]), gl.STATIC_DRAW);
    const texCoordBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]), gl.STATIC_DRAW);
    // We don't use texStorage2D here because texImage2D seems faster
    // to upload video texture than texSubImage2D even though the latter
    // is supposed to be the recommended way:
    // https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/WebGL_best_practices#use_texstorage_to_create_textures
    const inputFrameTexture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, inputFrameTexture);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    // TODO Rename segmentation and person mask to be more specific
    const segmentationTexture = createTexture(gl, gl.RGBA8, segmentationWidth, segmentationHeight);
    const personMaskTexture = createTexture(gl, gl.RGBA8, frameWidth, frameHeight);
    const resizingStage = buildResizingStage(gl, vertexShader, positionBuffer, texCoordBuffer, tflite, segmentationConfig);
    const loadSegmentationStage = buildSoftmaxStage(gl, vertexShader, positionBuffer, texCoordBuffer, tflite, segmentationTexture, segmentationConfig);
    const jointBilateralFilterStage = buildJointBilateralFilterStage(gl, vertexShader, positionBuffer, texCoordBuffer, segmentationTexture, personMaskTexture, canvas, segmentationConfig);
    const backgroundStage = backgroundFilter === 'blur'
        ? buildBackgroundBlurStage(gl, vertexShader, positionBuffer, texCoordBuffer, personMaskTexture, canvas, blurLevel || 'high')
        : buildBackgroundImageStage(gl, positionBuffer, texCoordBuffer, personMaskTexture, backgroundImage, canvas);
    function render() {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, inputFrameTexture);
        // texImage2D seems faster than texSubImage2D to upload
        // video texture
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, videoSource);
        gl.bindVertexArray(vertexArray);
        resizingStage.render();
        tflite._runInference();
        loadSegmentationStage.render();
        jointBilateralFilterStage.render();
        backgroundStage.render();
    }
    function updatePostProcessingConfig() {
        jointBilateralFilterStage.updateSigmaSpace(1);
        jointBilateralFilterStage.updateSigmaColor(0.1);
        if (backgroundFilter === 'image') {
            const backgroundImageStage = backgroundStage;
            backgroundImageStage.updateCoverage([0.5, 0.75]);
            backgroundImageStage.updateLightWrapping(0.3);
            backgroundImageStage.updateBlendMode('screen');
        }
        else if (backgroundFilter === 'blur') {
            const backgroundBlurStage = backgroundStage;
            backgroundBlurStage.updateCoverage([0.5, 0.75]);
        }
        else {
            // TODO Handle no background in a separate pipeline path
            const backgroundImageStage = backgroundStage;
            backgroundImageStage.updateCoverage([0, 0.9999]);
            backgroundImageStage.updateLightWrapping(0);
        }
    }
    function cleanUp() {
        backgroundStage.cleanUp();
        jointBilateralFilterStage.cleanUp();
        loadSegmentationStage.cleanUp();
        resizingStage.cleanUp();
        gl.deleteTexture(personMaskTexture);
        gl.deleteTexture(segmentationTexture);
        gl.deleteTexture(inputFrameTexture);
        gl.deleteBuffer(texCoordBuffer);
        gl.deleteBuffer(positionBuffer);
        gl.deleteVertexArray(vertexArray);
        gl.deleteShader(vertexShader);
    }
    return { render, updatePostProcessingConfig, cleanUp };
}

var SegmentationLevel;
(function (SegmentationLevel) {
    SegmentationLevel["LOW"] = "low";
    SegmentationLevel["HIGH"] = "high";
})(SegmentationLevel || (SegmentationLevel = {}));
const getSegmentationParams = (level) => {
    if (level === SegmentationLevel.HIGH) {
        return { width: 256, height: 144 };
    }
    return { width: 160, height: 96 };
};

function createRenderer(tflite, videoSource, targetCanvas, options, onError) {
    const { backgroundFilter, backgroundImage, backgroundBlurLevel, segmentationLevel = SegmentationLevel.HIGH, fps = 30, } = options;
    if (backgroundFilter === 'image' && !backgroundImage) {
        throw new Error(`backgroundImage element is required when backgroundFilter is image`);
    }
    const pipeline = buildWebGL2Pipeline(videoSource, backgroundImage, backgroundBlurLevel, backgroundFilter, targetCanvas, tflite, getSegmentationParams(segmentationLevel));
    const timers = new WorkerTimer({ useWorker: true });
    const id = timers.setInterval(() => {
        try {
            pipeline.render();
            if (backgroundFilter === 'image') {
                pipeline.updatePostProcessingConfig();
            }
        }
        catch (error) {
            onError?.(error);
        }
    }, Math.floor(1000 / (fps <= 0 ? 30 : fps)));
    return {
        dispose: () => {
            pipeline.cleanUp();
            timers.clearInterval(id);
            timers.destroy();
        },
    };
}

const createTFLiteSIMDModule = (__Module) => {
  __Module = __Module || {};

  var _scriptDir =
    typeof document !== 'undefined' && document.currentScript
      ? document.currentScript.src
      : undefined;

  var Module = typeof __Module != 'undefined' ? __Module : {};
  var readyPromiseResolve, readyPromiseReject;
  Module['ready'] = new Promise(function (resolve, reject) {
    readyPromiseResolve = resolve;
    readyPromiseReject = reject;
  });
  var moduleOverrides = Object.assign({}, Module);
  var thisProgram = './this.program';
  var quit_ = (status, toThrow) => {
    throw toThrow;
  };
  var ENVIRONMENT_IS_WEB = true;
  var scriptDirectory = '';

  function locateFile(path) {
    if (Module['locateFile']) {
      return Module['locateFile'](path, scriptDirectory);
    }
    return scriptDirectory + path;
  }

  var readBinary;
  {
    if (typeof document != 'undefined' && document.currentScript) {
      scriptDirectory = document.currentScript.src;
    }
    if (_scriptDir) {
      scriptDirectory = _scriptDir;
    }
    if (scriptDirectory.indexOf('blob:') !== 0) {
      scriptDirectory = scriptDirectory.substr(
        0,
        scriptDirectory.replace(/[?#].*/, '').lastIndexOf('/') + 1,
      );
    } else {
      scriptDirectory = '';
    }
  }
  var out = Module['print'] || console.log.bind(console);
  var err = Module['printErr'] || console.warn.bind(console);
  Object.assign(Module, moduleOverrides);
  moduleOverrides = null;
  if (Module['arguments']) Module['arguments'];
  if (Module['thisProgram']) thisProgram = Module['thisProgram'];
  if (Module['quit']) quit_ = Module['quit'];
  var wasmBinary;
  if (Module['wasmBinary']) wasmBinary = Module['wasmBinary'];
  Module['noExitRuntime'] || true;
  if (typeof WebAssembly != 'object') {
    abort('no native wasm support detected');
  }
  var wasmMemory;
  var ABORT = false;

  var UTF8Decoder =
    typeof TextDecoder != 'undefined' ? new TextDecoder('utf8') : undefined;

  function UTF8ArrayToString(heapOrArray, idx, maxBytesToRead) {
    var endIdx = idx + maxBytesToRead;
    var endPtr = idx;
    while (heapOrArray[endPtr] && !(endPtr >= endIdx)) ++endPtr;
    if (endPtr - idx > 16 && heapOrArray.buffer && UTF8Decoder) {
      return UTF8Decoder.decode(heapOrArray.subarray(idx, endPtr));
    }
    var str = '';
    while (idx < endPtr) {
      var u0 = heapOrArray[idx++];
      if (!(u0 & 128)) {
        str += String.fromCharCode(u0);
        continue;
      }
      var u1 = heapOrArray[idx++] & 63;
      if ((u0 & 224) == 192) {
        str += String.fromCharCode(((u0 & 31) << 6) | u1);
        continue;
      }
      var u2 = heapOrArray[idx++] & 63;
      if ((u0 & 240) == 224) {
        u0 = ((u0 & 15) << 12) | (u1 << 6) | u2;
      } else {
        u0 =
          ((u0 & 7) << 18) | (u1 << 12) | (u2 << 6) | (heapOrArray[idx++] & 63);
      }
      if (u0 < 65536) {
        str += String.fromCharCode(u0);
      } else {
        var ch = u0 - 65536;
        str += String.fromCharCode(55296 | (ch >> 10), 56320 | (ch & 1023));
      }
    }
    return str;
  }

  var buffer, HEAP8, HEAPU8, HEAPU32;

  function updateGlobalBufferAndViews(buf) {
    buffer = buf;
    Module['HEAP8'] = HEAP8 = new Int8Array(buf);
    Module['HEAP16'] = new Int16Array(buf);
    Module['HEAP32'] = new Int32Array(buf);
    Module['HEAPU8'] = HEAPU8 = new Uint8Array(buf);
    Module['HEAPU16'] = new Uint16Array(buf);
    Module['HEAPU32'] = HEAPU32 = new Uint32Array(buf);
    Module['HEAPF32'] = new Float32Array(buf);
    Module['HEAPF64'] = new Float64Array(buf);
  }

  Module['INITIAL_MEMORY'] || 16777216;
  var __ATPRERUN__ = [];
  var __ATINIT__ = [];
  var __ATPOSTRUN__ = [];

  function preRun() {
    if (Module['preRun']) {
      if (typeof Module['preRun'] == 'function')
        Module['preRun'] = [Module['preRun']];
      while (Module['preRun'].length) {
        addOnPreRun(Module['preRun'].shift());
      }
    }
    callRuntimeCallbacks(__ATPRERUN__);
  }

  function initRuntime() {
    callRuntimeCallbacks(__ATINIT__);
  }

  function postRun() {
    if (Module['postRun']) {
      if (typeof Module['postRun'] == 'function')
        Module['postRun'] = [Module['postRun']];
      while (Module['postRun'].length) {
        addOnPostRun(Module['postRun'].shift());
      }
    }
    callRuntimeCallbacks(__ATPOSTRUN__);
  }

  function addOnPreRun(cb) {
    __ATPRERUN__.unshift(cb);
  }

  function addOnInit(cb) {
    __ATINIT__.unshift(cb);
  }

  function addOnPostRun(cb) {
    __ATPOSTRUN__.unshift(cb);
  }

  var runDependencies = 0;
  var dependenciesFulfilled = null;

  function addRunDependency(id) {
    runDependencies++;
    if (Module['monitorRunDependencies']) {
      Module['monitorRunDependencies'](runDependencies);
    }
  }

  function removeRunDependency(id) {
    runDependencies--;
    if (Module['monitorRunDependencies']) {
      Module['monitorRunDependencies'](runDependencies);
    }
    if (runDependencies == 0) {
      if (dependenciesFulfilled) {
        var callback = dependenciesFulfilled;
        dependenciesFulfilled = null;
        callback();
      }
    }
  }

  function abort(what) {
    {
      if (Module['onAbort']) {
        Module['onAbort'](what);
      }
    }
    what = 'Aborted(' + what + ')';
    err(what);
    ABORT = true;
    what += '. Build with -sASSERTIONS for more info.';
    var e = new WebAssembly.RuntimeError(what);
    readyPromiseReject(e);
    throw e;
  }

  var dataURIPrefix = 'data:application/octet-stream;base64,';

  function isDataURI(filename) {
    return filename.startsWith(dataURIPrefix);
  }

  var wasmBinaryFile;
  wasmBinaryFile = 'tflite-simd.wasm';
  if (!isDataURI(wasmBinaryFile)) {
    wasmBinaryFile = locateFile(wasmBinaryFile);
  }

  function getBinary(file) {
    try {
      if (file == wasmBinaryFile && wasmBinary) {
        return new Uint8Array(wasmBinary);
      }
      if (readBinary) ;
      throw 'both async and sync fetching of the wasm failed';
      // eslint-disable-next-line @typescript-eslint/no-shadow
    } catch (err) {
      abort(err);
    }
  }

  function getBinaryPromise() {
    if (!wasmBinary && (ENVIRONMENT_IS_WEB)) {
      if (typeof fetch == 'function') {
        return fetch(wasmBinaryFile, { credentials: 'same-origin' })
          .then(function (response) {
            if (!response['ok']) {
              throw (
                "failed to load wasm binary file at '" + wasmBinaryFile + "'"
              );
            }
            return response['arrayBuffer']();
          })
          .catch(function () {
            return getBinary(wasmBinaryFile);
          });
      }
    }
    return Promise.resolve().then(function () {
      return getBinary(wasmBinaryFile);
    });
  }

  function createWasm() {
    var info = {
      env: asmLibraryArg,
      wasi_snapshot_preview1: asmLibraryArg,
    };

    function receiveInstance(instance, module) {
      var exports = instance.exports;
      Module['asm'] = exports;
      wasmMemory = Module['asm']['memory'];
      updateGlobalBufferAndViews(wasmMemory.buffer);
      Module['asm']['__indirect_function_table'];
      addOnInit(Module['asm']['__wasm_call_ctors']);
      removeRunDependency();
    }

    addRunDependency();

    function receiveInstantiationResult(result) {
      receiveInstance(result['instance']);
    }

    function instantiateArrayBuffer(receiver) {
      return getBinaryPromise()
        .then(function (binary) {
          return WebAssembly.instantiate(binary, info);
        })
        .then(function (instance) {
          return instance;
        })
        .then(receiver, function (reason) {
          err('failed to asynchronously prepare wasm: ' + reason);
          abort(reason);
        });
    }

    function instantiateAsync() {
      if (
        !wasmBinary &&
        typeof WebAssembly.instantiateStreaming == 'function' &&
        !isDataURI(wasmBinaryFile) &&
        typeof fetch == 'function'
      ) {
        return fetch(wasmBinaryFile, { credentials: 'same-origin' }).then(
          function (response) {
            var result = WebAssembly.instantiateStreaming(response, info);
            return result.then(receiveInstantiationResult, function (reason) {
              err('wasm streaming compile failed: ' + reason);
              err('falling back to ArrayBuffer instantiation');
              return instantiateArrayBuffer(receiveInstantiationResult);
            });
          },
        );
      } else {
        return instantiateArrayBuffer(receiveInstantiationResult);
      }
    }

    if (Module['instantiateWasm']) {
      try {
        var exports = Module['instantiateWasm'](info, receiveInstance);
        return exports;
      } catch (e) {
        err('Module.instantiateWasm callback failed with error: ' + e);
        readyPromiseReject(e);
      }
    }
    instantiateAsync().catch(readyPromiseReject);
    return {};
  }

  function ExitStatus(status) {
    this.name = 'ExitStatus';
    this.message = 'Program terminated with exit(' + status + ')';
    this.status = status;
  }

  function callRuntimeCallbacks(callbacks) {
    while (callbacks.length > 0) {
      callbacks.shift()(Module);
    }
  }

  function __dlinit(main_dso_handle) {}

  var dlopenMissingError =
    'To use dlopen, you need enable dynamic linking, see https://github.com/emscripten-core/emscripten/wiki/Linking';

  function __dlopen_js(filename, flag) {
    abort(dlopenMissingError);
  }

  function __dlsym_js(handle, symbol) {
    abort(dlopenMissingError);
  }

  var nowIsMonotonic = true;

  function __emscripten_get_now_is_monotonic() {
    return nowIsMonotonic;
  }

  function __mmap_js(len, prot, flags, fd, off, allocated) {
    return -52;
  }

  function __munmap_js(addr, len, prot, flags, fd, offset) {}

  function _abort() {
    abort('');
  }

  function _emscripten_date_now() {
    return Date.now();
  }

  function getHeapMax() {
    return 2147483648;
  }

  function _emscripten_get_heap_max() {
    return getHeapMax();
  }

  var _emscripten_get_now;
  _emscripten_get_now = () => performance.now();

  function _emscripten_memcpy_big(dest, src, num) {
    HEAPU8.copyWithin(dest, src, src + num);
  }

  function emscripten_realloc_buffer(size) {
    try {
      wasmMemory.grow((size - buffer.byteLength + 65535) >>> 16);
      updateGlobalBufferAndViews(wasmMemory.buffer);
      return 1;
    } catch (e) {}
  }

  function _emscripten_resize_heap(requestedSize) {
    var oldSize = HEAPU8.length;
    requestedSize = requestedSize >>> 0;
    var maxHeapSize = getHeapMax();
    if (requestedSize > maxHeapSize) {
      return false;
    }
    let alignUp = (x, multiple) => x + ((multiple - (x % multiple)) % multiple);
    for (var cutDown = 1; cutDown <= 4; cutDown *= 2) {
      var overGrownHeapSize = oldSize * (1 + 0.2 / cutDown);
      overGrownHeapSize = Math.min(
        overGrownHeapSize,
        requestedSize + 100663296,
      );
      var newSize = Math.min(
        maxHeapSize,
        alignUp(Math.max(requestedSize, overGrownHeapSize), 65536),
      );
      var replacement = emscripten_realloc_buffer(newSize);
      if (replacement) {
        return true;
      }
    }
    return false;
  }

  var ENV = {};

  function getExecutableName() {
    return thisProgram || './this.program';
  }

  function getEnvStrings() {
    if (!getEnvStrings.strings) {
      var lang =
        (
          (typeof navigator == 'object' &&
            navigator.languages &&
            navigator.languages[0]) ||
          'C'
        ).replace('-', '_') + '.UTF-8';
      var env = {
        USER: 'web_user',
        LOGNAME: 'web_user',
        PATH: '/',
        PWD: '/',
        HOME: '/home/web_user',
        LANG: lang,
        _: getExecutableName(),
      };
      for (var x in ENV) {
        if (ENV[x] === undefined) delete env[x];
        else env[x] = ENV[x];
      }
      var strings = [];
      for (var x in env) {
        strings.push(x + '=' + env[x]);
      }
      getEnvStrings.strings = strings;
    }
    return getEnvStrings.strings;
  }

  // eslint-disable-next-line @typescript-eslint/no-shadow
  function writeAsciiToMemory(str, buffer, dontAddNull) {
    for (var i = 0; i < str.length; ++i) {
      HEAP8[buffer++ >> 0] = str.charCodeAt(i);
    }
    HEAP8[buffer >> 0] = 0;
  }

  function _environ_get(__environ, environ_buf) {
    var bufSize = 0;
    getEnvStrings().forEach(function (string, i) {
      var ptr = environ_buf + bufSize;
      HEAPU32[(__environ + i * 4) >> 2] = ptr;
      writeAsciiToMemory(string, ptr);
      bufSize += string.length + 1;
    });
    return 0;
  }

  function _environ_sizes_get(penviron_count, penviron_buf_size) {
    var strings = getEnvStrings();
    HEAPU32[penviron_count >> 2] = strings.length;
    var bufSize = 0;
    strings.forEach(function (string) {
      bufSize += string.length + 1;
    });
    HEAPU32[penviron_buf_size >> 2] = bufSize;
    return 0;
  }

  function _proc_exit(code) {
    quit_(code, new ExitStatus(code));
  }

  function exitJS(status, implicit) {
    _proc_exit(status);
  }

  var _exit = exitJS;

  function _fd_close(fd) {
    return 52;
  }

  function _fd_seek(fd, offset_low, offset_high, whence, newOffset) {
    return 70;
  }

  var printCharBuffers = [null, [], []];

  function printChar(stream, curr) {
    // eslint-disable-next-line @typescript-eslint/no-shadow
    var buffer = printCharBuffers[stream];
    if (curr === 0 || curr === 10) {
      (stream === 1 ? out : err)(UTF8ArrayToString(buffer, 0));
      buffer.length = 0;
    } else {
      buffer.push(curr);
    }
  }

  function _fd_write(fd, iov, iovcnt, pnum) {
    var num = 0;
    for (var i = 0; i < iovcnt; i++) {
      var ptr = HEAPU32[iov >> 2];
      var len = HEAPU32[(iov + 4) >> 2];
      iov += 8;
      for (var j = 0; j < len; j++) {
        printChar(fd, HEAPU8[ptr + j]);
      }
      num += len;
    }
    HEAPU32[pnum >> 2] = num;
    return 0;
  }

  function getRandomDevice() {
    if (
      typeof crypto == 'object' &&
      typeof crypto['getRandomValues'] == 'function'
    ) {
      var randomBuffer = new Uint8Array(1);
      return () => {
        crypto.getRandomValues(randomBuffer);
        return randomBuffer[0];
      };
    } else return () => abort('randomDevice');
  }

  // eslint-disable-next-line @typescript-eslint/no-shadow
  function _getentropy(buffer, size) {
    if (!_getentropy.randomDevice) {
      _getentropy.randomDevice = getRandomDevice();
    }
    for (var i = 0; i < size; i++) {
      HEAP8[(buffer + i) >> 0] = _getentropy.randomDevice();
    }
    return 0;
  }

  var asmLibraryArg = {
    _dlinit: __dlinit,
    _dlopen_js: __dlopen_js,
    _dlsym_js: __dlsym_js,
    _emscripten_get_now_is_monotonic: __emscripten_get_now_is_monotonic,
    _mmap_js: __mmap_js,
    _munmap_js: __munmap_js,
    abort: _abort,
    emscripten_date_now: _emscripten_date_now,
    emscripten_get_heap_max: _emscripten_get_heap_max,
    emscripten_get_now: _emscripten_get_now,
    emscripten_memcpy_big: _emscripten_memcpy_big,
    emscripten_resize_heap: _emscripten_resize_heap,
    environ_get: _environ_get,
    environ_sizes_get: _environ_sizes_get,
    exit: _exit,
    fd_close: _fd_close,
    fd_seek: _fd_seek,
    fd_write: _fd_write,
    getentropy: _getentropy,
  };
  createWasm();
  (Module['___wasm_call_ctors'] = function () {
    return (Module['___wasm_call_ctors'] =
      Module['asm']['__wasm_call_ctors']).apply(null, arguments);
  });
  (Module['_getModelBufferMemoryOffset'] =
    function () {
      return (Module[
        '_getModelBufferMemoryOffset'
      ] =
        Module['asm']['getModelBufferMemoryOffset']).apply(null, arguments);
    });
  (Module['_getInputMemoryOffset'] = function () {
    return (Module['_getInputMemoryOffset'] =
      Module['asm']['getInputMemoryOffset']).apply(null, arguments);
  });
  (Module['_getInputHeight'] = function () {
    return (Module['_getInputHeight'] =
      Module['asm']['getInputHeight']).apply(null, arguments);
  });
  (Module['_getInputWidth'] = function () {
    return (Module['_getInputWidth'] =
      Module['asm']['getInputWidth']).apply(null, arguments);
  });
  (Module['_getInputChannelCount'] = function () {
    return (Module['_getInputChannelCount'] =
      Module['asm']['getInputChannelCount']).apply(null, arguments);
  });
  (Module['_getOutputMemoryOffset'] = function () {
    return (Module['_getOutputMemoryOffset'] =
      Module['asm']['getOutputMemoryOffset']).apply(null, arguments);
  });
  (Module['_getOutputHeight'] = function () {
    return (Module['_getOutputHeight'] =
      Module['asm']['getOutputHeight']).apply(null, arguments);
  });
  (Module['_getOutputWidth'] = function () {
    return (Module['_getOutputWidth'] =
      Module['asm']['getOutputWidth']).apply(null, arguments);
  });
  (Module['_getOutputChannelCount'] = function () {
    return (Module['_getOutputChannelCount'] =
      Module['asm']['getOutputChannelCount']).apply(null, arguments);
  });
  (Module['_loadModel'] = function () {
    return (Module['_loadModel'] =
      Module['asm']['loadModel']).apply(null, arguments);
  });
  (Module['_runInference'] = function () {
    return (Module['_runInference'] =
      Module['asm']['runInference']).apply(null, arguments);
  });
  (Module['_malloc'] = function () {
    return (Module['_malloc'] = Module['asm']['malloc']).apply(
      null,
      arguments,
    );
  });
  (Module['___errno_location'] = function () {
    return (Module['___errno_location'] =
      Module['asm']['__errno_location']).apply(null, arguments);
  });
  (Module['___dl_seterr'] = function () {
    return (Module['___dl_seterr'] =
      Module['asm']['__dl_seterr']).apply(null, arguments);
  });
  (Module['stackSave'] = function () {
    return (Module['stackSave'] = Module['asm']['stackSave']).apply(
      null,
      arguments,
    );
  });
  (Module['stackRestore'] = function () {
    return (Module['stackRestore'] =
      Module['asm']['stackRestore']).apply(null, arguments);
  });
  (Module['stackAlloc'] = function () {
    return (Module['stackAlloc'] =
      Module['asm']['stackAlloc']).apply(null, arguments);
  });
  (Module['dynCall_jjj'] = function () {
    return (Module['dynCall_jjj'] =
      Module['asm']['dynCall_jjj']).apply(null, arguments);
  });
  (Module['dynCall_jiii'] = function () {
    return (Module['dynCall_jiii'] =
      Module['asm']['dynCall_jiii']).apply(null, arguments);
  });
  (Module['dynCall_iiiijj'] = function () {
    return (Module['dynCall_iiiijj'] =
      Module['asm']['dynCall_iiiijj']).apply(null, arguments);
  });
  (Module['dynCall_viijj'] = function () {
    return (Module['dynCall_viijj'] =
      Module['asm']['dynCall_viijj']).apply(null, arguments);
  });
  (Module['dynCall_viiijjj'] = function () {
    return (Module['dynCall_viiijjj'] =
      Module['asm']['dynCall_viiijjj']).apply(null, arguments);
  });
  (Module['dynCall_iijjiiii'] = function () {
    return (Module['dynCall_iijjiiii'] =
      Module['asm']['dynCall_iijjiiii']).apply(null, arguments);
  });
  (Module['dynCall_jiji'] = function () {
    return (Module['dynCall_jiji'] =
      Module['asm']['dynCall_jiji']).apply(null, arguments);
  });
  var calledRun;
  dependenciesFulfilled = function runCaller() {
    if (!calledRun) run();
    if (!calledRun) dependenciesFulfilled = runCaller;
  };

  function run(args) {
    if (runDependencies > 0) {
      return;
    }
    preRun();
    if (runDependencies > 0) {
      return;
    }

    function doRun() {
      if (calledRun) return;
      calledRun = true;
      Module['calledRun'] = true;
      if (ABORT) return;
      initRuntime();
      readyPromiseResolve(Module);
      if (Module['onRuntimeInitialized']) Module['onRuntimeInitialized']();
      postRun();
    }

    if (Module['setStatus']) {
      Module['setStatus']('Running...');
      setTimeout(function () {
        setTimeout(function () {
          Module['setStatus']('');
        }, 1);
        doRun();
      }, 1);
    } else {
      doRun();
    }
  }

  if (Module['preInit']) {
    if (typeof Module['preInit'] == 'function')
      Module['preInit'] = [Module['preInit']];
    while (Module['preInit'].length > 0) {
      Module['preInit'].pop()();
    }
  }
  run();

  return __Module.ready;
};

const version = "0.7.2";
const packageName = "@stream-io/video-filters-web";

// @ts-expect-error - module is not declared
// This is a WebAssembly module compiled from the TensorFlow Lite C++ library.
const createTFLite = createTFLiteSIMDModule;
const loadTFLite = async (options = {}) => {
    const { basePath = `https://unpkg.com/${packageName}@${version}/tf`, tfFilePath = `${basePath}/tflite/tflite-simd.wasm`, modelFilePath = `${basePath}/models/segm_full_v679.tflite`, } = options;
    const [tfLite, model] = await Promise.all([
        createTFLite({ locateFile: () => tfFilePath }),
        fetchModel(modelFilePath),
    ]);
    const modelBufferOffset = tfLite._getModelBufferMemoryOffset();
    tfLite.HEAPU8.set(new Uint8Array(model), modelBufferOffset);
    tfLite._loadModel(model.byteLength);
    return tfLite;
};
let lastModelFilePath$1 = '';
let modelFileCache$1;
const fetchModel = async (modelFilePath) => {
    const model = modelFilePath === lastModelFilePath$1 && modelFileCache$1
        ? modelFileCache$1
        : await fetch(modelFilePath).then((r) => r.arrayBuffer());
    // Cache the model file for future use.
    modelFileCache$1 = model;
    lastModelFilePath$1 = modelFilePath;
    return model;
};

let lastModelFilePath = '';
let modelFileCache;
const loadMediaPipe = async (options = {}) => {
    const { basePath = `https://unpkg.com/${packageName}@${version}/mediapipe`, modelPath = `${basePath}/models/selfie_segmenter_landscape.tflite`, } = options;
    const model = modelPath === lastModelFilePath && modelFileCache
        ? modelFileCache
        : await fetch(modelPath).then((r) => r.arrayBuffer());
    modelFileCache = model;
    lastModelFilePath = modelPath;
    return model;
};

/**
 * Maps blur level to blur strength values.
 */
const BACKGROUND_BLUR_MAP = {
    low: 3,
    medium: 5,
    high: 7,
};

class WebGLRenderer {
    constructor(canvas) {
        this.running = false;
        this.currentStateIndex = 0;
        this.backgroundRenderInfo = null;
        this.activeBackgroundSourceIdentifier = null;
        this.canvas = canvas;
        const gl = this.canvas.getContext('webgl2', {
            alpha: false,
            antialias: false,
            desynchronized: true,
        });
        if (!gl)
            throw new Error('WebGL2 not supported');
        this.gl = gl;
        const stateUpdateVertexShaderSource = `attribute vec2 a_position; attribute vec2 a_texCoord; varying vec2 v_texCoord; void main() { gl_Position = vec4(a_position, 0.0, 1.0); v_texCoord = a_texCoord; }`;
        const stateUpdateFragmentShaderSource = `
      precision mediump float;
      varying vec2 v_texCoord;
      uniform sampler2D u_categoryTexture;
      uniform sampler2D u_confidenceTexture;
      uniform sampler2D u_prevStateTexture;
      uniform float u_smoothingFactor;
      uniform float u_smoothstepMin;
      uniform float u_smoothstepMax;
      uniform int u_selfieModel;

      void main() {
        vec2 prevCoord = vec2(v_texCoord.x, 1.0 - v_texCoord.y);
        float categoryValue = texture2D(u_categoryTexture, v_texCoord).r;
        float confidenceValue = texture2D(u_confidenceTexture, v_texCoord).r;

        if (u_selfieModel == 1) {
            categoryValue = 1.0 - categoryValue;
            confidenceValue = 1.0 - confidenceValue;
        }

        if (categoryValue > 0.0) {
            categoryValue = 1.0;
            confidenceValue = 1.0 - confidenceValue;
        }

        float nonLinearConfidence = smoothstep(u_smoothstepMin, u_smoothstepMax, confidenceValue);
        float prevCategoryValue = texture2D(u_prevStateTexture, prevCoord).r;
        float alpha = u_smoothingFactor * nonLinearConfidence;
        float newCategoryValue = alpha * categoryValue + (1.0 - alpha) * prevCategoryValue;

        gl_FragColor = vec4(newCategoryValue, 0.0, 0.0, 0.0);
      }
    `;
        this.stateUpdateProgram = this.createAndLinkProgram(stateUpdateVertexShaderSource, stateUpdateFragmentShaderSource);
        this.stateUpdateLocations = {
            position: gl.getAttribLocation(this.stateUpdateProgram, 'a_position'),
            texCoord: gl.getAttribLocation(this.stateUpdateProgram, 'a_texCoord'),
            categoryTexture: gl.getUniformLocation(this.stateUpdateProgram, 'u_categoryTexture'),
            confidenceTexture: gl.getUniformLocation(this.stateUpdateProgram, 'u_confidenceTexture'),
            prevStateTexture: gl.getUniformLocation(this.stateUpdateProgram, 'u_prevStateTexture'),
            smoothingFactor: gl.getUniformLocation(this.stateUpdateProgram, 'u_smoothingFactor'),
            smoothstepMin: gl.getUniformLocation(this.stateUpdateProgram, 'u_smoothstepMin'),
            smoothstepMax: gl.getUniformLocation(this.stateUpdateProgram, 'u_smoothstepMax'),
            selfieModel: gl.getUniformLocation(this.stateUpdateProgram, 'u_selfieModel'),
        };
        const maskRefineVertexShaderSource = stateUpdateVertexShaderSource;
        const maskRefineFragmentShaderSource = `
      precision mediump float;
      varying vec2 v_texCoord;

      uniform sampler2D u_maskTexture;
      uniform sampler2D u_frameTexture;
      uniform vec2 u_texelSize;
      uniform float u_sigmaSpatial;
      uniform float u_sigmaRange;

      void main() {
        vec2 flippedCoord = v_texCoord;
        vec3 centerPixelColor = texture2D(u_frameTexture, v_texCoord).rgb;
        float totalWeight = 0.0;
        float weightedMaskSum = 0.0;

        for (int offsetX = -2; offsetX <= 2; offsetX++) {
          for (int offsetY = -2; offsetY <= 2; offsetY++) {
            vec2 shift = vec2(float(offsetX), float(offsetY)) * u_texelSize;
            vec2 frameCoord = v_texCoord + shift;
            vec2 maskCoord = flippedCoord + shift;

            vec3 neighborPixelColor = texture2D(u_frameTexture, frameCoord).rgb;
            float neighborMaskValue = texture2D(u_maskTexture, maskCoord).r;

            float spatialWeight = exp(-dot(shift, shift) / (2.0 * u_sigmaSpatial * u_sigmaSpatial));
            vec3 colorDifference = neighborPixelColor - centerPixelColor;
            float rangeWeight = exp(-(dot(colorDifference, colorDifference)) / (2.0 * u_sigmaRange * u_sigmaRange));

            float combinedWeight = spatialWeight * rangeWeight;
            weightedMaskSum += neighborMaskValue * combinedWeight;
            totalWeight += combinedWeight;
          }
        }

        float refinedMaskValue = weightedMaskSum / max(totalWeight, 1e-6);
        gl_FragColor = vec4(refinedMaskValue, refinedMaskValue, refinedMaskValue, 1.0);
      }
    `;
        this.maskRefineProgram = this.createAndLinkProgram(maskRefineVertexShaderSource, maskRefineFragmentShaderSource);
        this.maskRefineLocations = {
            position: gl.getAttribLocation(this.maskRefineProgram, 'a_position'),
            texCoord: gl.getAttribLocation(this.maskRefineProgram, 'a_texCoord'),
            maskTexture: gl.getUniformLocation(this.maskRefineProgram, 'u_maskTexture'),
            frameTexture: gl.getUniformLocation(this.maskRefineProgram, 'u_frameTexture'),
            texelSize: gl.getUniformLocation(this.maskRefineProgram, 'u_texelSize'),
            sigmaSpatial: gl.getUniformLocation(this.maskRefineProgram, 'u_sigmaSpatial'),
            sigmaRange: gl.getUniformLocation(this.maskRefineProgram, 'u_sigmaRange'),
        };
        const blurVertexShaderSource = stateUpdateVertexShaderSource;
        const blurFragmentShaderSource = `
      precision highp float;
      varying vec2 v_texCoord;

      uniform sampler2D u_image;
      uniform sampler2D u_personMask;
      uniform vec2 u_texelSize;
      uniform float u_sigma;
      uniform float u_radiusScale;
      uniform vec2 u_direction;

      const int KERNEL_RADIUS = 10;

      float gauss(float x, float s) {
        return exp(-(x * x) / (2.0 * s * s));
      }

      void main() {
        vec2 maskCoord = u_direction.y > 0.5 ? vec2(v_texCoord.x, 1.0 - v_texCoord.y) : v_texCoord;
        float mCenter = texture2D(u_personMask, maskCoord).r;
        float wCenter = gauss(0.0, u_sigma);
        vec4 accum = texture2D(u_image, v_texCoord) * wCenter * (1.0 - mCenter);
        float weightSum = wCenter * (1.0 - mCenter);

        for (int i = 1; i <= KERNEL_RADIUS; i++) {
          float f = float(i);
          float offset = f * u_radiusScale;
          float w = gauss(offset, u_sigma);
          vec2 texOffset = u_direction * offset * u_texelSize;

          vec2 uvPlus = v_texCoord + texOffset;
          vec2 maskCoordPlus = u_direction.y > 0.5 ? vec2(uvPlus.x, 1.0 - uvPlus.y) : uvPlus;
          float mPlus = texture2D(u_personMask, maskCoordPlus).r;
          accum += texture2D(u_image, uvPlus) * w * (1.0 - mPlus);
          weightSum += w * (1.0 - mPlus);

          vec2 uvMinus = v_texCoord - texOffset;
          vec2 maskCoordMinus = u_direction.y > 0.5 ? vec2(uvMinus.x, 1.0 - uvMinus.y) : uvMinus;
          float mMinus = texture2D(u_personMask, maskCoordMinus).r;
          accum += texture2D(u_image, uvMinus) * w * (1.0 - mMinus);
          weightSum += w * (1.0 - mMinus);
        }

        vec4 blurred = accum / max(weightSum, 1e-6);
        gl_FragColor = blurred;
      }
    `;
        this.blurProgram = this.createAndLinkProgram(blurVertexShaderSource, blurFragmentShaderSource);
        this.blurLocations = {
            position: gl.getAttribLocation(this.blurProgram, 'a_position'),
            texCoord: gl.getAttribLocation(this.blurProgram, 'a_texCoord'),
            image: gl.getUniformLocation(this.blurProgram, 'u_image'),
            personMask: gl.getUniformLocation(this.blurProgram, 'u_personMask'),
            texelSize: gl.getUniformLocation(this.blurProgram, 'u_texelSize'),
            sigma: gl.getUniformLocation(this.blurProgram, 'u_sigma'),
            radiusScale: gl.getUniformLocation(this.blurProgram, 'u_radiusScale'),
            direction: gl.getUniformLocation(this.blurProgram, 'u_direction'),
        };
        const blendVertexShaderSource = stateUpdateVertexShaderSource;
        const blendFragmentShaderSource = `
      precision mediump float;
      varying vec2 v_texCoord;

      uniform sampler2D u_frameTexture;
      uniform sampler2D u_currentStateTexture;
      uniform sampler2D u_backgroundTexture;
      uniform vec2 u_bgImageDimensions;
      uniform vec2 u_canvasDimensions;
      uniform float u_borderSmooth;
      uniform float u_bgBlur;
      uniform float u_bgBlurRadius;
      uniform int u_enabled;

      vec4 getMixedFragColor(vec2 bgTexCoord, vec2 categoryCoord, vec2 offset) {
          vec4 backgroundColor = texture2D(u_backgroundTexture, bgTexCoord + offset);
          vec4 frameColor = texture2D(u_frameTexture, v_texCoord + offset);
          float categoryValue = texture2D(u_currentStateTexture, categoryCoord + offset).r;
          return mix(backgroundColor, frameColor, categoryValue);
      }

      void main() {
        if (u_enabled == 0) {
          gl_FragColor = texture2D(u_frameTexture, v_texCoord);
          return;
        }

        vec2 categoryCoord = v_texCoord;
        float categoryValue = texture2D(u_currentStateTexture, categoryCoord).r;

        float canvasAspect = u_canvasDimensions.x / u_canvasDimensions.y;
          float bgAspect = u_bgImageDimensions.x / u_bgImageDimensions.y;

          vec2 bgTexCoord = v_texCoord;
          float scaleX = 1.0;
          float scaleY = 1.0;
          float offsetX = 0.0;
          float offsetY = 0.0;

          if (canvasAspect < bgAspect) {
              scaleY = 1.0;
              scaleX = bgAspect / canvasAspect;
              offsetX = (1.0 - scaleX) / 2.0;
          } else {
              scaleX = 1.0;
              scaleY = canvasAspect / bgAspect;
              offsetY = (1.0 - scaleY) / 2.0;
          }

          bgTexCoord = vec2((v_texCoord.x - offsetX) / scaleX, (v_texCoord.y - offsetY) / scaleY);
          gl_FragColor = getMixedFragColor(bgTexCoord, categoryCoord, vec2(0.0, 0.0));
    }`;
        this.blendProgram = this.createAndLinkProgram(blendVertexShaderSource, blendFragmentShaderSource);
        this.blendLocations = {
            position: gl.getAttribLocation(this.blendProgram, 'a_position'),
            texCoord: gl.getAttribLocation(this.blendProgram, 'a_texCoord'),
            frameTexture: gl.getUniformLocation(this.blendProgram, 'u_frameTexture'),
            currentStateTexture: gl.getUniformLocation(this.blendProgram, 'u_currentStateTexture'),
            backgroundTexture: gl.getUniformLocation(this.blendProgram, 'u_backgroundTexture'),
            bgImageDimensions: gl.getUniformLocation(this.blendProgram, 'u_bgImageDimensions'),
            canvasDimensions: gl.getUniformLocation(this.blendProgram, 'u_canvasDimensions'),
            borderSmooth: gl.getUniformLocation(this.blendProgram, 'u_borderSmooth'),
            bgBlur: gl.getUniformLocation(this.blendProgram, 'u_bgBlur'),
            bgBlurRadius: gl.getUniformLocation(this.blendProgram, 'u_bgBlurRadius'),
            enabled: gl.getUniformLocation(this.blendProgram, 'u_enabled'),
        };
        this.positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]), gl.STATIC_DRAW);
        this.texCoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]), gl.STATIC_DRAW);
        this.storedStateTextures = Array.from({ length: 2 }, () => {
            const tex = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, tex);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array([0, 0, 0, 255]));
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            return tex;
        });
        gl.bindTexture(gl.TEXTURE_2D, null);
        this.fbo = gl.createFramebuffer();
        this.refineFbo = gl.createFramebuffer();
        const refinedTex = gl.createTexture();
        this.frameTexture = gl.createTexture();
        if (!refinedTex)
            throw new Error('Failed to create refined mask texture');
        gl.bindTexture(gl.TEXTURE_2D, refinedTex);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        gl.bindTexture(gl.TEXTURE_2D, null);
        this.refinedMaskTexture = refinedTex;
        const mkColorTex = () => {
            const t = gl.createTexture();
            if (!t)
                throw new Error('Failed to create blur texture');
            gl.bindTexture(gl.TEXTURE_2D, t);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            gl.bindTexture(gl.TEXTURE_2D, null);
            return t;
        };
        this.blurTexture1 = mkColorTex();
        this.blurTexture2 = mkColorTex();
        const mkFbo = (tex) => {
            const fb = gl.createFramebuffer();
            if (!fb || !tex)
                throw new Error('Failed to create blur FBO');
            gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
            gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            return fb;
        };
        this.blurFbo1 = mkFbo(this.blurTexture1);
        this.blurFbo2 = mkFbo(this.blurTexture2);
        this.running = true;
    }
    createAndLinkProgram(vsSource, fsSource) {
        const vs = this.createShader(this.gl.VERTEX_SHADER, vsSource);
        const fs = this.createShader(this.gl.FRAGMENT_SHADER, fsSource);
        const prog = this.gl.createProgram();
        if (!prog)
            throw new Error('Failed to create program');
        this.gl.attachShader(prog, vs);
        this.gl.attachShader(prog, fs);
        this.gl.linkProgram(prog);
        if (!this.gl.getProgramParameter(prog, this.gl.LINK_STATUS)) {
            console.error('Program link error:', this.gl.getProgramInfoLog(prog));
            this.gl.deleteProgram(prog);
            throw new Error('Link fail');
        }
        this.gl.detachShader(prog, vs);
        this.gl.detachShader(prog, fs);
        this.gl.deleteShader(vs);
        this.gl.deleteShader(fs);
        return prog;
    }
    createShader(type, source) {
        const shader = this.gl.createShader(type);
        if (!shader)
            throw new Error(`Failed to create shader type: ${type}`);
        this.gl.shaderSource(shader, source);
        this.gl.compileShader(shader);
        if (!this.gl.getShaderParameter(shader, this.gl.COMPILE_STATUS)) {
            console.error('Shader compile error:', this.gl.getShaderInfoLog(shader));
            this.gl.deleteShader(shader);
            throw new Error('Failed to compile shader');
        }
        return shader;
    }
    createColorTexture(r, g, b, a) {
        const texture = this.gl.createTexture();
        if (!texture)
            throw new Error('Failed to create texture for color');
        this.gl.bindTexture(this.gl.TEXTURE_2D, texture);
        const pixel = new Uint8Array([r, g, b, a]);
        this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, 1, 1, 0, this.gl.RGBA, this.gl.UNSIGNED_BYTE, pixel);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.NEAREST);
        this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.NEAREST);
        this.gl.bindTexture(this.gl.TEXTURE_2D, null);
        return { texture, color: [r, g, b, a] };
    }
    updateBackgroundIfNeeded(newSource) {
        const gl = this.gl;
        let newIdentifier;
        if (!newSource) {
            const [r, g, b, a] = WebGLRenderer.DEFAULT_BG_COLOR;
            newIdentifier = `color(${r},${g},${b},${a})`;
        }
        else {
            newIdentifier = newSource.url;
        }
        if (newIdentifier === this.activeBackgroundSourceIdentifier &&
            this.backgroundRenderInfo) {
            return;
        }
        if (this.backgroundRenderInfo) {
            gl.deleteTexture(this.backgroundRenderInfo.texture);
            this.backgroundRenderInfo = null;
        }
        this.activeBackgroundSourceIdentifier = newIdentifier;
        if (!newSource) {
            const [r, g, b, a] = WebGLRenderer.DEFAULT_BG_COLOR;
            const colorTexData = this.createColorTexture(r, g, b, a);
            this.backgroundRenderInfo = {
                type: 'color',
                texture: colorTexData.texture,
                color: colorTexData.color,
            };
            this.activeBackgroundSourceIdentifier = `color(${r},${g},${b},${a})`;
        }
        else {
            if (newSource.type === 'image') {
                const { media, url } = newSource;
                const texture = this.gl.createTexture();
                if (!texture) {
                    throw new Error('Failed to create texture object for image.');
                }
                this.gl.bindTexture(this.gl.TEXTURE_2D, texture);
                this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, this.gl.RGBA, this.gl.UNSIGNED_BYTE, media);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
                this.gl.bindTexture(this.gl.TEXTURE_2D, null);
                this.backgroundRenderInfo = {
                    type: 'image',
                    texture,
                    width: media.width,
                    height: media.height,
                    url,
                };
            }
            else if (newSource.type === 'video') {
                const { media, url } = newSource;
                const canvas = new OffscreenCanvas(1, 1);
                const ctx = canvas.getContext('2d');
                const writer = new WritableStream({
                    write(videoFrame) {
                        canvas.width = videoFrame.codedWidth;
                        canvas.height = videoFrame.codedHeight;
                        ctx?.drawImage(videoFrame, 0, 0);
                        videoFrame.close();
                    },
                    close() {
                        console.log('[virtual-background] video background close');
                    },
                });
                media.pipeTo(writer).catch((err) => {
                    console.error('media.pipeTo(writer) error', err);
                });
                const texture = this.gl.createTexture();
                if (!texture)
                    throw new Error('Failed to create texture for video');
                this.gl.bindTexture(this.gl.TEXTURE_2D, texture);
                this.gl.texImage2D(this.gl.TEXTURE_2D, 0, this.gl.RGBA, 1, 1, 0, this.gl.RGBA, this.gl.UNSIGNED_BYTE, null);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_S, this.gl.CLAMP_TO_EDGE);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_WRAP_T, this.gl.CLAMP_TO_EDGE);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MIN_FILTER, this.gl.LINEAR);
                this.gl.texParameteri(this.gl.TEXTURE_2D, this.gl.TEXTURE_MAG_FILTER, this.gl.LINEAR);
                this.gl.bindTexture(this.gl.TEXTURE_2D, null);
                this.backgroundRenderInfo = {
                    type: 'video',
                    texture,
                    url,
                    media,
                    canvas,
                };
            }
        }
        if (!this.backgroundRenderInfo) {
            console.error('Critical: backgroundRenderInfo is null after processing new source. Setting default color.');
            const [r, g, b, a] = WebGLRenderer.DEFAULT_BG_COLOR;
            const colorTexData = this.createColorTexture(r, g, b, a);
            this.backgroundRenderInfo = {
                type: 'color',
                texture: colorTexData.texture,
                color: colorTexData.color,
            };
            this.activeBackgroundSourceIdentifier = `color(${r},${g},${b},${a})`;
        }
    }
    render(videoFrame, options, categoryTexture, confidenceTexture) {
        if (!this.running)
            return;
        const { gl, fbo, frameTexture, storedStateTextures, stateUpdateProgram, stateUpdateLocations, refineFbo, refinedMaskTexture, maskRefineProgram, maskRefineLocations, blendProgram, blendLocations, blurFbo1, blurFbo2, blurTexture1, blurTexture2, } = this;
        const { displayWidth: width, displayHeight: height } = videoFrame;
        if (this.canvas.width !== width || this.canvas.height !== height) {
            this.canvas.width = width;
            this.canvas.height = height;
        }
        if (!categoryTexture || !confidenceTexture) {
            gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
            gl.useProgram(blendProgram);
            const frame = gl.createTexture();
            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, frame);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, videoFrame);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
            gl.uniform1i(blendLocations.frameTexture, 0);
            gl.uniform1i(blendLocations.enabled, 0);
            gl.enableVertexAttribArray(blendLocations.position);
            gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
            gl.vertexAttribPointer(blendLocations.position, 2, gl.FLOAT, false, 0, 0);
            gl.enableVertexAttribArray(blendLocations.texCoord);
            gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
            gl.vertexAttribPointer(blendLocations.texCoord, 2, gl.FLOAT, false, 0, 0);
            gl.drawArrays(gl.TRIANGLES, 0, 6);
            gl.deleteTexture(frame);
            gl.activeTexture(gl.TEXTURE0);
            gl.bindTexture(gl.TEXTURE_2D, null);
            return;
        }
        const readStateIndex = this.currentStateIndex;
        const writeStateIndex = (this.currentStateIndex + 1) % 2;
        const prevStateTexture = storedStateTextures[readStateIndex];
        const newStateTexture = storedStateTextures[writeStateIndex];
        this.updateBackgroundIfNeeded(options.backgroundSource);
        gl.bindFramebuffer(gl.FRAMEBUFFER, fbo);
        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, newStateTexture, 0);
        gl.bindTexture(gl.TEXTURE_2D, newStateTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
        gl.viewport(0, 0, width, height);
        gl.useProgram(stateUpdateProgram);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, categoryTexture);
        gl.uniform1i(stateUpdateLocations.categoryTexture, 0);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, confidenceTexture);
        gl.uniform1i(stateUpdateLocations.confidenceTexture, 1);
        gl.activeTexture(gl.TEXTURE2);
        gl.bindTexture(gl.TEXTURE_2D, prevStateTexture);
        gl.uniform1i(stateUpdateLocations.prevStateTexture, 2);
        gl.uniform1f(stateUpdateLocations.smoothingFactor, 0.8);
        gl.uniform1f(stateUpdateLocations.smoothstepMin, 0.6);
        gl.uniform1f(stateUpdateLocations.smoothstepMax, 0.9);
        gl.uniform1i(stateUpdateLocations.selfieModel, options.isSelfieMode ? 1 : 0);
        gl.enableVertexAttribArray(stateUpdateLocations.position);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.vertexAttribPointer(stateUpdateLocations.position, 2, gl.FLOAT, false, 0, 0);
        gl.enableVertexAttribArray(stateUpdateLocations.texCoord);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.vertexAttribPointer(stateUpdateLocations.texCoord, 2, gl.FLOAT, false, 0, 0);
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        gl.bindFramebuffer(gl.FRAMEBUFFER, refineFbo);
        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, refinedMaskTexture, 0);
        gl.bindTexture(gl.TEXTURE_2D, refinedMaskTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
        gl.viewport(0, 0, width, height);
        gl.useProgram(maskRefineProgram);
        gl.enableVertexAttribArray(maskRefineLocations.position);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.vertexAttribPointer(maskRefineLocations.position, 2, gl.FLOAT, false, 0, 0);
        gl.enableVertexAttribArray(maskRefineLocations.texCoord);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.vertexAttribPointer(maskRefineLocations.texCoord, 2, gl.FLOAT, false, 0, 0);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, newStateTexture);
        gl.uniform1i(maskRefineLocations.maskTexture, 0);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, frameTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, videoFrame);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        gl.uniform1i(maskRefineLocations.frameTexture, 1);
        gl.uniform2f(maskRefineLocations.texelSize, 1.0 / width, 1.0 / height);
        gl.uniform1f(maskRefineLocations.sigmaSpatial, 2.0);
        gl.uniform1f(maskRefineLocations.sigmaRange, 0.1);
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        gl.disableVertexAttribArray(maskRefineLocations.position);
        gl.disableVertexAttribArray(maskRefineLocations.texCoord);
        let backgroundTexToUse;
        let bgWToSend = width;
        let bgHToSend = height;
        if (options.bgBlur > 0 && options.bgBlurRadius > 0) {
            const downscale = 0.5;
            const blurW = Math.floor(width * downscale);
            const blurH = Math.floor(height * downscale);
            gl.bindTexture(gl.TEXTURE_2D, blurTexture1);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, blurW, blurH, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
            gl.bindTexture(gl.TEXTURE_2D, blurTexture2);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, blurW, blurH, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
            const KERNEL_RADIUS = 10.0;
            const radiusScale = Math.max(0.0, options.bgBlurRadius) / KERNEL_RADIUS;
            gl.useProgram(this.blurProgram);
            gl.enableVertexAttribArray(this.blurLocations.position);
            gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
            gl.vertexAttribPointer(this.blurLocations.position, 2, gl.FLOAT, false, 0, 0);
            gl.enableVertexAttribArray(this.blurLocations.texCoord);
            gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
            gl.vertexAttribPointer(this.blurLocations.texCoord, 2, gl.FLOAT, false, 0, 0);
            gl.activeTexture(gl.TEXTURE1);
            gl.bindTexture(gl.TEXTURE_2D, refinedMaskTexture);
            gl.uniform1i(this.blurLocations.personMask, 1);
            gl.uniform1f(this.blurLocations.sigma, options.bgBlur * 0.7);
            gl.uniform1f(this.blurLocations.radiusScale, radiusScale);
            const blurPasses = [
                {
                    direction: [1.0, 0.0],
                    input: frameTexture,
                    output: blurFbo1,
                    texelSize: [1.0 / width, 1.0 / height],
                },
                {
                    direction: [0.0, 1.0],
                    input: blurTexture1,
                    output: blurFbo2,
                    texelSize: [1.0 / blurW, 1.0 / blurH],
                },
                {
                    direction: [1.0, 0.0],
                    input: blurTexture2,
                    output: blurFbo1,
                    texelSize: [1.0 / blurW, 1.0 / blurH],
                },
                {
                    direction: [0.0, 1.0],
                    input: blurTexture1,
                    output: blurFbo2,
                    texelSize: [1.0 / blurW, 1.0 / blurH],
                },
            ];
            for (const pass of blurPasses) {
                gl.bindFramebuffer(gl.FRAMEBUFFER, pass.output);
                gl.viewport(0, 0, blurW, blurH);
                gl.activeTexture(gl.TEXTURE0);
                gl.bindTexture(gl.TEXTURE_2D, pass.input);
                gl.uniform1i(this.blurLocations.image, 0);
                gl.uniform2f(this.blurLocations.texelSize, pass.texelSize[0], pass.texelSize[1]);
                gl.uniform2f(this.blurLocations.direction, pass.direction[0], pass.direction[1]);
                gl.drawArrays(gl.TRIANGLES, 0, 6);
            }
            backgroundTexToUse = blurTexture2;
            bgWToSend = blurW;
            bgHToSend = blurH;
        }
        else if (options.backgroundSource && this.backgroundRenderInfo) {
            backgroundTexToUse = this.backgroundRenderInfo.texture;
            if (this.backgroundRenderInfo.type === 'video') {
                const { canvas } = this.backgroundRenderInfo;
                bgWToSend = canvas.width || width;
                bgHToSend = canvas.height || height;
            }
            else if (this.backgroundRenderInfo.type === 'image') {
                bgWToSend = this.backgroundRenderInfo.width;
                bgHToSend = this.backgroundRenderInfo.height;
            }
            else {
                bgWToSend = width;
                bgHToSend = height;
            }
        }
        else {
            backgroundTexToUse = this.backgroundRenderInfo?.texture ?? null;
        }
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
        gl.useProgram(blendProgram);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, frameTexture);
        gl.uniform1i(blendLocations.frameTexture, 0);
        gl.uniform1f(blendLocations.borderSmooth, 0);
        gl.uniform1f(blendLocations.bgBlur, options.bgBlur);
        gl.uniform1f(blendLocations.bgBlurRadius, options.bgBlurRadius);
        gl.uniform1i(blendLocations.enabled, 1);
        gl.activeTexture(gl.TEXTURE1);
        gl.bindTexture(gl.TEXTURE_2D, refinedMaskTexture);
        gl.uniform1i(blendLocations.currentStateTexture, 1);
        if (backgroundTexToUse) {
            gl.activeTexture(gl.TEXTURE2);
            gl.bindTexture(gl.TEXTURE_2D, backgroundTexToUse);
            gl.uniform1i(blendLocations.backgroundTexture, 2);
            gl.uniform2f(blendLocations.bgImageDimensions, bgWToSend, bgHToSend);
            gl.uniform2f(blendLocations.canvasDimensions, width, height);
        }
        else {
            gl.uniform2f(blendLocations.bgImageDimensions, width, height);
            gl.uniform2f(blendLocations.canvasDimensions, width, height);
        }
        gl.enableVertexAttribArray(blendLocations.position);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.vertexAttribPointer(blendLocations.position, 2, gl.FLOAT, false, 0, 0);
        gl.enableVertexAttribArray(blendLocations.texCoord);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.vertexAttribPointer(blendLocations.texCoord, 2, gl.FLOAT, false, 0, 0);
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        for (let i = 0; i < 3; ++i) {
            gl.activeTexture(gl.TEXTURE0 + i);
            gl.bindTexture(gl.TEXTURE_2D, null);
        }
        this.currentStateIndex = writeStateIndex;
    }
    close() {
        if (!this.running)
            return;
        this.running = false;
        const { gl, fbo, refineFbo, refinedMaskTexture, blurFbo1, blurFbo2 } = this;
        gl.clearColor(0, 0, 0, 0);
        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        if (fbo)
            gl.deleteFramebuffer(fbo);
        if (refineFbo)
            gl.deleteFramebuffer(refineFbo);
        if (blurFbo1)
            gl.deleteFramebuffer(blurFbo1);
        if (blurFbo2)
            gl.deleteFramebuffer(blurFbo2);
        gl.deleteProgram(this.stateUpdateProgram);
        gl.deleteProgram(this.maskRefineProgram);
        gl.deleteProgram(this.blurProgram);
        gl.deleteProgram(this.blendProgram);
        if (this.positionBuffer)
            gl.deleteBuffer(this.positionBuffer);
        if (this.texCoordBuffer)
            gl.deleteBuffer(this.texCoordBuffer);
        if (refinedMaskTexture)
            gl.deleteTexture(refinedMaskTexture);
        if (this.blurTexture1)
            gl.deleteTexture(this.blurTexture1);
        if (this.blurTexture2)
            gl.deleteTexture(this.blurTexture2);
        this.storedStateTextures.forEach((t) => t && gl.deleteTexture(t));
        this.storedStateTextures.splice(0, this.storedStateTextures.length);
        if (this.backgroundRenderInfo?.texture) {
            gl.deleteTexture(this.backgroundRenderInfo.texture);
            this.backgroundRenderInfo = null;
        }
        this.activeBackgroundSourceIdentifier = null;
    }
}
WebGLRenderer.DEFAULT_BG_COLOR = [33, 150, 243, 255];

/**
 * Fallback video processor for browsers that do not support MediaStreamTrackGenerator.
 *
 * Produces a video MediaStreamTrack sourced from a canvas and exposes
 * a WritableStream<VideoFrame> on track.writable for writing frames.
 */
class FallbackGenerator {
    constructor({ kind, signalTarget }) {
        if (kind !== 'video') {
            throw new Error('Only video tracks are supported');
        }
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d', { desynchronized: true });
        if (!ctx) {
            throw new Error('Failed to get 2D context from canvas');
        }
        const mediaStream = canvas.captureStream();
        const track = mediaStream.getVideoTracks()[0];
        const height = signalTarget?.getSettings().height;
        const width = signalTarget?.getSettings().width;
        if (height && width) {
            canvas.height = height;
            canvas.width = width;
        }
        if (!track) {
            throw new Error('Failed to create canvas track');
        }
        if (signalTarget) {
            signalTarget.addEventListener('ended', () => {
                track.stop();
            });
        }
        track.writable = new WritableStream({
            write: (frame) => {
                if (canvas.width !== frame.displayWidth ||
                    canvas.height !== frame.displayHeight) {
                    canvas.width = frame.displayWidth;
                    canvas.height = frame.displayHeight;
                }
                ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
                frame.close();
            },
            abort: () => {
                track.stop();
            },
            close: () => {
                track.stop();
            },
        });
        return track;
    }
}
const TrackGenerator = typeof MediaStreamTrackGenerator !== 'undefined'
    ? MediaStreamTrackGenerator
    : FallbackGenerator;

/**
 * Fallback implementation for browsers without MediaStreamTrackGenerator.
 *
 * Produces a video MediaStreamTrack sourced from a canvas and exposes a
 * WritableStream<VideoFrame> on track.writable. Written frames are drawn
 * into the canvas and update the underlying track automatically.
 */
class FallbackProcessor {
    constructor({ track }) {
        this.close = () => {
            this.video.pause();
            this.video.srcObject = null;
            this.video.src = '';
            this.workerTimer.destroy();
        };
        if (!track)
            throw new Error('MediaStreamTrack is required');
        if (track.kind !== 'video') {
            throw new Error('MediaStreamTrack must be video');
        }
        let running = true;
        this.video = document.createElement('video');
        this.video.muted = true;
        this.video.playsInline = true;
        this.video.srcObject = new MediaStream([track]);
        const canvas = new OffscreenCanvas(1, 1);
        const ctx = canvas.getContext('2d');
        if (!ctx)
            throw new Error('Failed to get 2D context from OffscreenCanvas');
        let timestamp = 0;
        const frameRate = track.getSettings().frameRate || 30;
        let frameDuration = 1000 / frameRate;
        this.workerTimer = new WorkerTimer({ useWorker: true });
        this.readable = new ReadableStream({
            start: async () => {
                await Promise.all([
                    this.video.play(),
                    new Promise((r) => this.video.addEventListener('loadeddata', r, { once: true })),
                ]);
                frameDuration = 1000 / (track.getSettings().frameRate || 30);
                timestamp = performance.now();
            },
            pull: async (controller) => {
                if (!running) {
                    controller.close();
                    this.close();
                    return;
                }
                const delta = performance.now() - timestamp;
                if (delta <= frameDuration) {
                    await new Promise((r) => this.workerTimer.setTimeout(r, frameDuration - delta));
                }
                timestamp = performance.now();
                if (canvas.width !== this.video.videoWidth ||
                    canvas.height !== this.video.videoHeight) {
                    canvas.width = this.video.videoWidth;
                    canvas.height = this.video.videoHeight;
                }
                ctx.drawImage(this.video, 0, 0);
                try {
                    const frame = new VideoFrame(canvas, {
                        timestamp: Math.round(this.video.currentTime * 1000000),
                    });
                    controller.enqueue(frame);
                }
                catch (err) {
                    running = false;
                    controller.error(err);
                    this.close();
                }
            },
            cancel: () => {
                running = false;
                this.close();
            },
        });
    }
}
const TrackProcessor = typeof MediaStreamTrackProcessor !== 'undefined'
    ? MediaStreamTrackProcessor
    : FallbackProcessor;

/**
 * Base class for real-time video filters.
 *
 * It sets up the full pipeline that reads frames from the input track,
 * processes them, and outputs a new track with your effect applied. Subclasses
 * only need to implement `initialize` (run once before processing starts) and
 * `transform` (called for every frame).
 *
 * Everything elsecanvas setup, performance tracking, error handling, and
 * clean shutdown is handled for you. Calling `start()` returns a processed
 * `MediaStreamTrack` ready to use.
 */
class BaseVideoProcessor {
    /**
     * Constructs a new instance.
     */
    constructor(track, hooks = {}) {
        this.track = track;
        this.abortController = new AbortController();
        this.frames = 0;
        this.delayTotal = 0;
        this.lastStatsTime = 0;
        this.processor = new TrackProcessor({ track });
        this.generator = new TrackGenerator({
            kind: 'video',
            signalTarget: track,
        });
        this.hooks = hooks;
    }
    async start() {
        const { readable } = this.processor;
        const { writable } = this.generator;
        const { width = 1280, height = 720 } = this.track.getSettings();
        this.canvas = new OffscreenCanvas(width, height);
        await this.initialize();
        const transformStream = new TransformStream({
            transform: async (frame, controller) => {
                try {
                    if (this.abortController.signal.aborted)
                        return frame.close();
                    if (this.canvas.width !== frame.displayWidth ||
                        this.canvas.height !== frame.displayHeight) {
                        this.canvas.width = frame.displayWidth;
                        this.canvas.height = frame.displayHeight;
                    }
                    const processed = await this.transform(frame);
                    controller.enqueue(processed);
                }
                catch (e) {
                    this.hooks.onError?.(e);
                }
                finally {
                    frame.close();
                }
            },
            flush: () => this.onFlush(),
        });
        readable
            .pipeThrough(transformStream, { signal: this.abortController.signal })
            .pipeTo(writable, { signal: this.abortController.signal })
            .catch((e) => {
            if (e.name !== 'AbortError' && e.name !== 'InvalidStateError') {
                console.error(`[${this.processorName}] Error processing track:`, e);
                this.hooks.onError?.(e);
            }
        });
        return this.generator;
    }
    stop() {
        this.abortController.abort();
        this.generator.stop();
        this.onStop();
    }
    updateStats(delay) {
        this.frames++;
        this.delayTotal += delay;
        const now = performance.now();
        if (this.lastStatsTime === 0) {
            this.lastStatsTime = now;
            return;
        }
        if (now - this.lastStatsTime >= 1000) {
            const avgDelay = Math.round((this.delayTotal / this.frames) * 100) / 100;
            const fps = Math.round((1000 * this.frames) / (now - this.lastStatsTime));
            this.hooks.onStats?.({ delay: avgDelay, fps, timestamp: now });
            this.frames = 0;
            this.delayTotal = 0;
            this.lastStatsTime = now;
        }
    }
    onFlush() { }
    onStop() { }
    get processorName() {
        return 'base-processor';
    }
}

/**
 * Wraps a video MediaStreamTrack in a real-time processing pipeline.
 * Incoming frames are processed through a transformer and re-emitted
 * on a new MediaStreamVideoTrack for downstream consumption.
 */
class VirtualBackground extends BaseVideoProcessor {
    constructor(track, options = {}, hooks = {}) {
        super(track, hooks);
        this.options = options;
        this.segmenter = null;
        this.isSegmenterReady = false;
        this.latestCategoryMask = undefined;
        this.latestConfidenceMask = undefined;
        this.lastFrameTime = -1;
    }
    async initialize() {
        this.webGlRenderer = new WebGLRenderer(this.canvas);
        await this.initializeSegmenter();
    }
    async initializeSegmenter() {
        try {
            this.opts = await this.initializeSegmenterOptions();
            const basePath = this.options.basePath ||
                `https://unpkg.com/${packageName}@${version}/mediapipe`;
            const model = this.options.modelPath ||
                `${basePath}/models/selfie_segmenter_landscape.tflite`;
            const fileset = await FilesetResolver.forVisionTasks(`${basePath}/wasm`);
            this.segmenter = await ImageSegmenter.createFromOptions(fileset, {
                baseOptions: { modelAssetPath: model, delegate: 'GPU' },
                runningMode: 'VIDEO',
                outputCategoryMask: true,
                outputConfidenceMasks: true,
                canvas: this.canvas,
            });
            this.isSegmenterReady = true;
        }
        catch (error) {
            console.error('[virtual-background] Segmenter init failed:', error);
            this.isSegmenterReady = false;
        }
    }
    async transform(frame) {
        const currentTime = frame.timestamp;
        const hasNewFrame = currentTime - this.lastFrameTime > 1000;
        this.lastFrameTime = currentTime;
        if (hasNewFrame && this.isSegmenterReady && this.segmenter) {
            const start = performance.now();
            await this.runSegmentation(frame);
            this.webGlRenderer.render(frame, this.opts, this.latestCategoryMask, this.latestConfidenceMask);
            this.updateStats(performance.now() - start);
        }
        return new VideoFrame(this.canvas, { timestamp: frame.timestamp });
    }
    async runSegmentation(frame) {
        if (!this.segmenter)
            return;
        return new Promise((resolve) => {
            const timestamp = Math.floor(performance.now());
            this.segmenter.segmentForVideo(frame, timestamp, (result) => {
                try {
                    this.latestCategoryMask = result.categoryMask?.getAsWebGLTexture();
                    this.latestConfidenceMask =
                        result.confidenceMasks?.[0]?.getAsWebGLTexture();
                }
                catch (err) {
                    console.error('[virtual-background] segmentation error:', err);
                    this.hooks.onError?.(err);
                }
                finally {
                    result.close();
                    resolve();
                }
            });
        });
    }
    async initializeSegmenterOptions() {
        const isSelfieMode = this.options.modelPath
            ? this.options.modelPath.includes('selfie_segmenter')
            : true;
        if (this.options.backgroundFilter === 'image') {
            const source = await this.loadBackground(this.options.backgroundImage);
            return {
                backgroundSource: source,
                bgBlur: 0,
                bgBlurRadius: 0,
                isSelfieMode,
            };
        }
        const blurLevel = this.options.backgroundBlurLevel;
        const strength = typeof blurLevel === 'string'
            ? BACKGROUND_BLUR_MAP[blurLevel]
            : Math.round(blurLevel ?? 5);
        return {
            backgroundSource: undefined,
            bgBlur: Math.min(strength * 1.5, 20),
            bgBlurRadius: Math.min(strength, 10),
            isSelfieMode,
        };
    }
    async loadBackground(url) {
        if (!url)
            return null;
        const result = await fetch(url);
        if (!result.ok)
            return null;
        return {
            type: 'image',
            media: await createImageBitmap(await result.blob()),
            url,
        };
    }
    onFlush() {
        this.destroySegmenter();
    }
    onStop() {
        this.webGlRenderer?.close();
        this.destroySegmenter();
    }
    destroySegmenter() {
        this.segmenter?.close();
        this.segmenter = null;
        this.isSegmenterReady = false;
    }
    get processorName() {
        return 'background-processor';
    }
}

/**
 * Simple WebGL renderer for full-screen Gaussian blur.
 * Uses a two-pass separable Gaussian blur (horizontal then vertical).
 * Optimized for moderation use cases by blurring at reduced resolution (15% scale)
 * and upscaling back to full resolution for output.
 */
class FullScreenBlurRenderer {
    constructor(canvas) {
        this.inputTexture = null;
        this.isRunning = false;
        this.targetWidth = 0;
        this.targetHeight = 0;
        this.weightCache = new Map();
        this.canvas = canvas;
        const gl = canvas.getContext('webgl2', {
            alpha: false,
            antialias: false,
            desynchronized: true,
        });
        if (!gl)
            throw new Error('WebGL2 not supported');
        this.gl = gl;
        const vertexShaderSource = `#version 300 es
      precision highp float;
      in vec2 a_position;
      in vec2 a_texCoord;
      out vec2 v_texCoord;
      void main() {
          v_texCoord = a_texCoord;
          gl_Position = vec4(a_position, 0.0, 1.0);
      }
    `;
        const fragmentShaderSource = `#version 300 es
      precision highp float;
      in vec2 v_texCoord;
      out vec4 outColor;
      uniform sampler2D u_image;
      uniform vec2 u_texelSize;
      uniform vec2 u_direction;
      uniform float u_weights[25];
      void main() {
          vec4 color = vec4(0.0);
          for (int i = -12; i <= 12; i++) {
              float w = u_weights[i + 12];
              if (w == 0.0) continue;
              vec2 offset = float(i) * u_direction * u_texelSize;
              color += w * texture(u_image, v_texCoord + offset);
          }
          outColor = color;
      }
    `;
        this.blurProgramHandle = this.createAndLinkProgram(vertexShaderSource, fragmentShaderSource);
        const passthroughFragmentShaderSource = `#version 300 es
      precision highp float;
      in vec2 v_texCoord;
      out vec4 outColor;
      uniform sampler2D u_image;
      void main() {
          outColor = texture(u_image, v_texCoord);
      }
    `;
        this.passthroughProgramHandle = this.createAndLinkProgram(vertexShaderSource, passthroughFragmentShaderSource);
        const blurProgram = this.blurProgramHandle;
        const passthroughProgram = this.passthroughProgramHandle;
        this.blurLocations = {
            positionLocation: gl.getAttribLocation(blurProgram, 'a_position'),
            texCoordLocation: gl.getAttribLocation(blurProgram, 'a_texCoord'),
            imageLocation: gl.getUniformLocation(blurProgram, 'u_image'),
            texelSizeLocation: gl.getUniformLocation(blurProgram, 'u_texelSize'),
            directionLocation: gl.getUniformLocation(blurProgram, 'u_direction'),
            weightsLocation: gl.getUniformLocation(blurProgram, 'u_weights'),
        };
        this.passthroughLocations = {
            positionLocation: gl.getAttribLocation(passthroughProgram, 'a_position'),
            texCoordLocation: gl.getAttribLocation(passthroughProgram, 'a_texCoord'),
            imageLocation: gl.getUniformLocation(passthroughProgram, 'u_image'),
        };
        this.positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]), gl.STATIC_DRAW);
        this.texCoordBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0]), gl.STATIC_DRAW);
        const createTexture2D = () => {
            const tex = gl.createTexture();
            if (!tex)
                throw new Error('Failed to create texture');
            gl.bindTexture(gl.TEXTURE_2D, tex);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
            gl.bindTexture(gl.TEXTURE_2D, null);
            return tex;
        };
        const createFramebufferForTexture = (tex) => {
            const fb = gl.createFramebuffer();
            if (!fb)
                throw new Error('Failed to create framebuffer');
            gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
            gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, tex, 0);
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            return fb;
        };
        this.pingTexture = createTexture2D();
        this.pongTexture = createTexture2D();
        this.pingFbo = createFramebufferForTexture(this.pingTexture);
        this.pongFbo = createFramebufferForTexture(this.pongTexture);
        this.inputTexture = createTexture2D();
        gl.useProgram(blurProgram);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.enableVertexAttribArray(this.blurLocations.positionLocation);
        gl.vertexAttribPointer(this.blurLocations.positionLocation, 2, gl.FLOAT, false, 0, 0);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.enableVertexAttribArray(this.blurLocations.texCoordLocation);
        gl.vertexAttribPointer(this.blurLocations.texCoordLocation, 2, gl.FLOAT, false, 0, 0);
        if (this.blurLocations.imageLocation) {
            gl.uniform1i(this.blurLocations.imageLocation, 0);
        }
        this.isRunning = true;
    }
    createAndLinkProgram(vsSource, fsSource) {
        const gl = this.gl;
        const vs = this.createShader(gl.VERTEX_SHADER, vsSource);
        const fs = this.createShader(gl.FRAGMENT_SHADER, fsSource);
        const prog = gl.createProgram();
        if (!prog)
            throw new Error('Failed to create program');
        gl.attachShader(prog, vs);
        gl.attachShader(prog, fs);
        gl.linkProgram(prog);
        if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
            throw new Error('Shader link failed: ' + gl.getProgramInfoLog(prog));
        }
        gl.deleteShader(vs);
        gl.deleteShader(fs);
        return prog;
    }
    createShader(type, source) {
        const gl = this.gl;
        const shader = gl.createShader(type);
        if (!shader)
            throw new Error('Failed to create shader');
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
            throw new Error('Shader compile failed: ' + gl.getShaderInfoLog(shader));
        }
        return shader;
    }
    getGaussianWeights(radius) {
        const r = Math.max(0, Math.min(radius | 0, 12));
        const cached = this.weightCache.get(r);
        if (cached)
            return cached;
        const weights = new Float32Array(25);
        if (r === 0) {
            weights[12] = 1.0;
            this.weightCache.set(r, weights);
            return weights;
        }
        const sigma = r * 0.6;
        let sum = 0;
        for (let i = -r; i <= r; i++) {
            const w = Math.exp(-(i * i) / (2 * sigma * sigma));
            weights[i + 12] = w;
            sum += w;
        }
        for (let i = -r; i <= r; i++) {
            weights[i + 12] /= sum;
        }
        this.weightCache.set(r, weights);
        return weights;
    }
    render(frame, radius) {
        if (!this.isRunning)
            return;
        const gl = this.gl;
        const width = frame.displayWidth;
        const height = frame.displayHeight;
        if (!width || !height)
            return;
        if (this.canvas.width !== width || this.canvas.height !== height) {
            this.canvas.width = width;
            this.canvas.height = height;
        }
        const scale = 0.15;
        const scaledWidth = Math.max(1, Math.floor(width * scale));
        const scaledHeight = Math.max(1, Math.floor(height * scale));
        if (scaledWidth !== this.targetWidth ||
            scaledHeight !== this.targetHeight) {
            this.targetWidth = scaledWidth;
            this.targetHeight = scaledHeight;
            gl.bindTexture(gl.TEXTURE_2D, this.pingTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, scaledWidth, scaledHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
            gl.bindTexture(gl.TEXTURE_2D, this.pongTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, scaledWidth, scaledHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
            gl.bindTexture(gl.TEXTURE_2D, null);
        }
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, this.inputTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, frame);
        gl.useProgram(this.blurProgramHandle);
        if (this.blurLocations.texelSizeLocation) {
            gl.uniform2f(this.blurLocations.texelSizeLocation, 1.0 / scaledWidth, 1.0 / scaledHeight);
        }
        const weights = this.getGaussianWeights(radius);
        if (this.blurLocations.weightsLocation) {
            gl.uniform1fv(this.blurLocations.weightsLocation, weights);
        }
        gl.viewport(0, 0, scaledWidth, scaledHeight);
        gl.bindFramebuffer(gl.FRAMEBUFFER, this.pingFbo);
        gl.bindTexture(gl.TEXTURE_2D, this.inputTexture);
        if (this.blurLocations.directionLocation) {
            gl.uniform2f(this.blurLocations.directionLocation, 1.0, 0.0);
        }
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        gl.bindFramebuffer(gl.FRAMEBUFFER, this.pongFbo);
        gl.bindTexture(gl.TEXTURE_2D, this.pingTexture);
        if (this.blurLocations.directionLocation) {
            gl.uniform2f(this.blurLocations.directionLocation, 0.0, 1.0);
        }
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.viewport(0, 0, width, height);
        gl.useProgram(this.passthroughProgramHandle);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.positionBuffer);
        gl.enableVertexAttribArray(this.passthroughLocations.positionLocation);
        gl.vertexAttribPointer(this.passthroughLocations.positionLocation, 2, gl.FLOAT, false, 0, 0);
        gl.bindBuffer(gl.ARRAY_BUFFER, this.texCoordBuffer);
        gl.enableVertexAttribArray(this.passthroughLocations.texCoordLocation);
        gl.vertexAttribPointer(this.passthroughLocations.texCoordLocation, 2, gl.FLOAT, false, 0, 0);
        gl.bindTexture(gl.TEXTURE_2D, this.pongTexture);
        if (this.passthroughLocations.imageLocation) {
            gl.uniform1i(this.passthroughLocations.imageLocation, 0);
        }
        gl.drawArrays(gl.TRIANGLES, 0, 6);
    }
    close() {
        if (!this.isRunning)
            return;
        this.isRunning = false;
        const gl = this.gl;
        if (this.pingFbo)
            gl.deleteFramebuffer(this.pingFbo);
        if (this.pongFbo)
            gl.deleteFramebuffer(this.pongFbo);
        if (this.pingTexture)
            gl.deleteTexture(this.pingTexture);
        if (this.pongTexture)
            gl.deleteTexture(this.pongTexture);
        if (this.inputTexture)
            gl.deleteTexture(this.inputTexture);
        if (this.positionBuffer)
            gl.deleteBuffer(this.positionBuffer);
        if (this.texCoordBuffer)
            gl.deleteBuffer(this.texCoordBuffer);
        gl.deleteProgram(this.blurProgramHandle);
        gl.deleteProgram(this.passthroughProgramHandle);
    }
}

/**
 * A video filter that applies a full-screen blur to each frame.
 *
 * It uses a WebGL renderer to blur the incoming camera track and outputs
 * a new track with the effect applied. Setup and frame handling are managed
 * by the base processor.
 */
class FullScreenBlur extends BaseVideoProcessor {
    /**
     * Creates a new full-screen blur processor for the given video track.
     *
     * @param track - The input camera track to blur.
     * @param options - Optional settings such as the blur radius.
     * @param hooks - Optional callbacks for stats and error reporting.
     */
    constructor(track, options = {}, hooks = {}) {
        super(track, hooks);
        this.blurRadius = options.blurRadius ?? 6;
    }
    async initialize() {
        this.blurRenderer = new FullScreenBlurRenderer(this.canvas);
    }
    async transform(frame) {
        this.blurRenderer.render(frame, this.blurRadius);
        return new VideoFrame(this.canvas, { timestamp: frame.timestamp });
    }
    onStop() {
        this.blurRenderer?.close();
    }
    get processorName() {
        return 'fullscreen-blur';
    }
}

export { BACKGROUND_BLUR_MAP, FullScreenBlur, SegmentationLevel, VirtualBackground, createRenderer, isMediaPipePlatformSupported, isPlatformSupported, loadMediaPipe, loadTFLite };
//# sourceMappingURL=index.es.js.map
